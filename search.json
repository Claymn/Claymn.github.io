[{"title":"在CentOS 7环境下编译Hadoop-2.7.7源码","url":"/2020/04/14/Hadoop-complie/","content":"最近在学习Hadoop，所以下载了源码自己进行编译安装。虽然官网提供编译好的二进制包，但是由于系统版本的细微差别。所以决定自己动手编译，日后的工作中难免会要自定义源码中的组件，先学习如何编译源码，避免以后踩坑。\n环境准备系统环境：CentOS 7Hadoop版本：Hadoop-2.7.7\n编译所需要的组件先解压从官网下载的hadoop-2.7.7-src.tar.gz\ntar -zxvf hadoop-2.7.7-src.tar.gz -C /root/apps \n/root/apps可以换成其他想要的路径。然后进入到解压后的目录，查看BUILDING.txt文件编译Hadoop所需要的组件：\nBuild instructions for Hadoop----------------------------------------------------------------------------------Requirements:* Unix System* JDK 1.7+* Maven 3.0 or later* Findbugs 1.3.9 (if running findbugs)* ProtocolBuffer 2.5.0* CMake 2.6 or newer (if compiling native code), must be 3.0 or newer on Mac* Zlib devel (if compiling native code)* openssl devel ( if compiling native hadoop-pipes and to get the best HDFS encryption performance )* Linux FUSE (Filesystem in Userspace) version 2.6 or above ( if compiling fuse_dfs )* Internet connection for first build (to fetch all Maven and Hadoop dependencies)\n所以，我们需要在编译Hadoop之前先安装JDK、Maven、Ant、Findbugs、ProtocolBuffer、CMake、openssl、ncurses-devel。\n编译需要的包yum install cmakeyum install openssl-develyum install ncurses-devel\n\n编译需要的软件JDKLinux系统自带有java环境，但是并不是我们需要的。所以要先删除系统中自带的Java环境。\n// 卸载OpenJDKrpm -qa|grep javarpm -e --nodeps xxxxxxxxxx(OpenJDK的包)\n卸载掉OpenJDK以后再开始安装JDK：\n// 解压tar -zxvf jdk-8u231-linux-x64.tar.gz -C /root/apps// 将JDK的路径添加到环境变量中去vi ~/.bash_profileexport JAVA_HOME=/root/apps/jdk1.8.0_231export PATH=$PATH:$JAVA_HOME/binexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tool.jarsource ~/.bash_profile//  检查安装是否成功java -version// 下面的结果就是已经安装成功java version &quot;1.8.0_231&quot;Java(TM) SE Runtime Environment (build 1.8.0_231-b11)Java HotSpot(TM) 64-Bit Server VM (build 25.231-b11, mixed mode)\nMaven// 解压tar -zxvf apache-maven-3.3.9-bin.tar.gz -C /root/apps// 将maven路径添加到环境变量中vi ~/.bash_profileexport MAVEN_HOME=/root/apps/apache-maven-3.3.9export PATH=$MAVEN_HOME/bin:$PATHsource ~/.bash_profile// 检查是否安装成功mvn -vApache Maven 3.3.9 (bb52d8502b132ec0a5a3f4c09453c07478323dc5; 2015-11-11T00:41:47+08:00)Maven home: /root/apps/apache-maven-3.3.9Java version: 1.8.0_231, vendor: Oracle CorporationJava home: /root/apps/jdk1.8.0_231/jreDefault locale: zh_CN, platform encoding: UTF-8OS name: &quot;linux&quot;, version: &quot;3.10.0-1062.el7.x86_64&quot;, arch: &quot;amd64&quot;, family: &quot;unix&quot;\n\nAnt// 解压tar -zxvf apache-ant-1.9.14-bin.tar.gz -C /root/apps// 将路径添加到环境变量中vi ~/.bash_profileexport ANT_HOME=/root/apps/apache-ant-1.9.14export PATH=$ANT_HOME/bin:$PATHsource ~/.bash_profile// 检查是否安装成功ant -versionApache Ant(TM) version 1.9.14 compiled on March 12 2019\nFindbugs// 解压tar -zxvf findbugs-3.0.1.tar.gz -C /root/apps// 将路径添加到环境变量中vi ~/.bash_profileexport FIND_HOME=/root/apps/findbugs-3.0.1export PATH=$FIND_HOME/bin:$PATHsource ~/.bash_profile// 检查是否安装成功findbugs -version3.0.1\n\nProtocol Buffer// 安装C++依赖yum install gcc-c++// 解压tar -zxvf protobuf-2.5.0.tar.gz -C /root/apps// 编译后的文件如果需要放到其他文件目录mkdir /root/apps/protobuf// 在解压后的目录下配置编译好的软件安装目录./configure --prefix=/root/apps/protobuf// 编译make make install// 将路径添加到环境变量中vi ~/.bash_profileexport PROTO_HOME=/root/apps/protobuf-2.5export PATH=$PROTO_HOME/bin:$PATHsource ~/.bash_profile// 检查是否安装成功protoc --versionlibprotoc 2.5.0\n#编译Hadoop\n// 解压tar -zxvf hadoop-2.7.7-src.tar.gz -C /root/appscd hadoop-2.7.7-src// 开始编译mvn package -Pdisk,native -DskipTests -Dtar\n编译需要比较长的一段时间，编译好的.tar.gz存放在/root/apps/hadoop-2.7.7-src/hadoop-dist/target里。可以将编译好的安装包放到其他路径解压安装。解压安装之后也要将路径配置到环境变量中去，最后可以使用hadoop version命令来检查是否安装成功。\n","categories":["Hadoop"],"tags":["Hadoop"]},{"title":"Linux常用命令","url":"/2021/11/17/Linux%20command/","content":"Linux常用指令总结pwdpwd命令是用来查看当前光标所在的目录。\n[root@Clay usr]# pwd/usr\ncdcd命令是用来切换目录的。\n1. cd path(绝对路径/相对路径):切换到指定路径。2. cd :切换到当前用户的家目录。3. cd ~:功能同上。4. cd -：切换到上一次输入命令时所在的目录。5. cd ../:回退到上一级目录。6. cd ../../:回退到上两级目录。\nlsls命令是用来查看当前目录下有哪些文件和文件夹（没有具体信息，只展示名称。）ls命令还有很多可选参数：\n1. -l: 查看当前目录下文件、文件夹的详细信息。也可以使用ll命令查看，但不是所有Linux系统都支持ll命令。如果系统不支持可以配置alias来实现。    1.1 ll 文件夹名称: 查看当前目录下指定文件夹内的详细信息。2. -a: 查看当前目录下的所有文件、文件夹及隐藏文件。3. -h: 查看文件的大小(不是文件夹)。4. -r: 为所展示的文件、文件夹排序。5. -t: 以修改时间排序，参与-r参数组合使用。\nmkdirmkdir命令是用来创建文件夹的。可以级联创健也可以并行创建多个文件夹。\n1. mkdir 1/2/3    在当前目录创建一个名为1的文件夹，1文件夹下还有2文件夹，2文件夹下有3文件夹。2. mkdir 1 2 3    在当前目录下创建1、2、3三个独立的文件夹。\nmv &amp; cpmv指令可以移动文件到指定的文件夹，也可以用来重命名文件。\n1. mv A.log B.log :将A.log文件重命名为B.log。2. mv A path : 将A文件移动到指定路径下。3. mv A目录 B目录 : 如果B路径已存在，则将A目录移动到B目录下；若B目录不存在，则将A目录重命名为B目录。\ncp命令主要用来拷贝、复制文件或文件夹。\n1. cp 源文件 路径 : 将源文件拷贝到指定路径下。2. cp 目录 路径 : 将文件夹拷贝到指定路径下。\n查看文件内容查看文件内容常用的三个命令分别是：cat、more和less。使用方法都是命令+文件名。其中cat是一次性将文件内容全部展示到终端中。more和less这是分页显示。\n创建文件touch可以使用touch来创建文件。\ntouch + A : 创建一个名为A的空文件。 \n使用vi或者vim命令vi或vim也可以创建一个文件。\nvi + 文件名 : 创建一个空文件，指令执行后会进入命令行模式。vim + 文件名 : 创建一个空文件，指令执行后会进入命令行模式。\nechoecho &quot; &quot; &gt; 文件名\n也可以使用上面的命令来创建一个空文件。但是需要注意的是使用echo创建的文件没有内容，但是使用ll命令查看时会有1字节。 \n&gt; &amp; &gt;&gt;&gt;表示覆盖，&gt;&gt;表示追加。\n1. echo &quot;hello&quot; &gt; clay.log : 将“hello”写入到clay.log文件中，并覆盖之前的内容。[root@Clay ~]# cat clay.logHello world![root@Clay ~]# echo &quot;hello&quot; &gt; clay.log[root@Clay ~]# cat clay.loghello2. echo &quot;hello&quot; &gt;&gt; clay.log : 将“hello”追加到clay.log文件中，不覆盖之前内容。[root@Clay ~]# cat clay.logHello world[root@Clay ~]# echo &quot;hello&quot; &gt;&gt; clay.log[root@Clay ~]# cat clay.logHello worldhello\n环境变量环境变量分为：全局环境变量和个人环境变量。全局环境变量的配置文件在更目录下的/etc/profile中配置。配置完成后使用\nsource /etc/profile\n使配置文件生效。\n个人环境变量的配置文件在用户家目录下的.bash_profile和.bashrc文件中。生效命令同样使source。\nrmrm命令用来删除文件或文件夹。\nrm clay.log : 删除clay.log文件，删除前进行询问。rm -f clay.log : 强制删除clay.log文件，不询问。rm -r clay : 删除clay目录下的所有文件，删除前进行询问。rm -rf clay : 删除clay目录下的所有文件，删除前不询问。\n使用rm命令删除的文件、文件夹时无法恢复的，所以rm -rf命令要慎用。\nhistoryhistory可以用来查看输入命令历史。\n[root@Clay ~]# history    1  ls    2  mysql    3  ll -a    4  pwd    5  clear    6  logout    7  ls    8  ll -a[root@Clay ~]#\n可以使用!序号来执行历史命令。\n[root@Clay ~]# !3ll -a总用量 52dr-xr-x---.  5 root root 4096 11月 16 20:06 .dr-xr-xr-x. 18 root root 4096 11月 13 10:48 ..-rw-------   1 root root 2872 11月 16 20:34 .bash_history-rw-r--r--.  1 root root   18 12月 29 2013 .bash_logout-rw-r--r--.  1 root root  176 12月 29 2013 .bash_profile-rw-r--r--.  1 root root  176 12月 29 2013 .bashrcdrwxr-xr-x   3 root root 4096 7月  11 2019 .cache-rw-r--r--   1 root root   18 11月 16 20:09 clay.log-rw-r--r--.  1 root root  100 12月 29 2013 .cshrcdrwxr-xr-x   2 root root 4096 7月  11 2019 .pip-rw-r--r--   1 root root  205 11月  3 09:54 .pydistutils.cfgdrwx------   2 root root 4096 7月  11 2019 .ssh-rw-r--r--.  1 root root  129 12月 29 2013 .tcshrc[root@Clay ~]#\n还可以使用history -c来清除历史记录。\n管道符|是管道符，作用是连接两个命令，以第一个命令的输出作为第二个命令的输入。\ncat clay.log | wc -l : 统计clay.log文件中有多少行。[root@Clay ~]# cat clay.logHello worldhello[root@Clay ~]# cat clay.log | wc -l2cat clay.log | grep world : 模糊匹配clay.log文件中的词world。[root@Clay ~]# cat clay.logHello worldhello[root@Clay ~]# cat clay.log | grep worldHello world\n查看文件大小在Linux中查看文件大小可以使用ll -h来查看，效果如下：\n[root@Clay ~]# ll -h总用量 4.0K-rw-r--r-- 1 root root 18 11月 16 20:09 clay.log\n但是ll -h只能用来查看文件的大小，不能查看文件夹的大小。如果想要查看文件夹的大小可以使用 du -sh命令来查看。\n[root@Clay ~]# du -sh388K\t.[root@Clay ~]# du -sh clay.log4.0K\tclay.log\n查找文件查找文件可以使用find命令来实现。\nfind / -name &#x27;*clay*&#x27; : 全局搜索包含clay的文件。（两个*表示模糊搜索）[root@Clay ~]# find / -name &#x27;*clay*&#x27;/root/clay.logfind ./ -name &#x27;*clay*&#x27; : 在当前目录中搜索含有clay的文件find 路径 -name &#x27;*clay*&#x27; : 在指定的路径中搜索含有clay的文件。\n在生产环境中慎用全局搜索，资源占用较大。\n关于vivi有三种模式：命令行模式、编辑模式和尾行模式。vi + 文件名进入命令行模式。在命令行模式下按i进入编辑模式，这个时候就可以对文件内容进行编辑。在编辑完成后按ESC键，从编辑模式退到命令行模式，再按shift + :进入尾行模式，按wq保存并退出。\na. 光标移动 :    1. 使用方向键来控制光标的位置。    2. gg : 跳转到首行的第一个字符。    3. G : 跳转到最后一行。    4. nG : 跳转到第n行。gg命令相当于1G。    5. 0 : 将光标移动到当前行的首位。    6. $ : 将光标移动到当前行的末尾。b. 删除、复制、粘贴 :    1. dd : 删除光标所在的整行。    2. ndd : 以光标所在行开始，向下删除n行内容。    3. yy : 复制光标所在的那一行。    4. nyy : 以光标所在行开始，向下复制n行。    5. p, P : p为将已复制的内容粘贴到光标所在行的下一行；P为将已复制的内容粘贴到光标所在行的上一行。    6. u : 还原上一个操作。c. 搜索与替换 :    1. /+关键词 : 从光标开始，检索与关键词陪陪的字符串。    2.s/ : 用法是s/关键词/关键词2/g，关键词1为检索的字符串，关键词2为要替换的字符串，g表示全局替换。 d.尾行模式 :    1. q! : 强制退出。    2. wq : 保存并退出。    3. wq! : 强制保存并退出，可用来修改read only文件。e. 使用gg dG可以清空文件。\nTips : 如果想要从另一个机器的文件中拷贝内容到当前机器的文件中时，一定要进入编辑模式中进行拷贝。直接在命令行模式下拷贝内容会导致内容丢失。\n清空文件在生产中可以使用 :\ncat /dev/null &gt; clay.log\n来清空clay.log文件。也可以使用使用vi命令，在命令行模式下使用gg dG来清空文件内容。切勿使用echo &quot;&quot; &gt; clay.log对文件进行清空。这个操作虽然会清空文件内容，但是在ll命令查看时仍会有1字节内容。\n[root@Clay ~]# lltotal 4-rw-r--r-- 1 root root 18 Nov 16 20:09 clay.log[root@Clay ~]# echo &quot;&quot; &gt; clay.log [root@Clay ~]# lltotal 4-rw-r--r-- 1 root root 1 Nov 17 20:09 clay.log[root@Clay ~]# \n查看系统状态使用df -h查看磁盘状态 : \n[root@Clay ~]# df -hFilesystem      Size  Used Avail Use% Mounted on/dev/vda1        40G  4.1G   34G  11% /devtmpfs        3.9G     0  3.9G   0% /devtmpfs           3.9G     0  3.9G   0% /dev/shmtmpfs           3.9G  476K  3.9G   1% /runtmpfs           3.9G     0  3.9G   0% /sys/fs/cgrouptmpfs           783M     0  783M   0% /run/user/0[root@Clay ~]# \n使用free -m查看内存 : \n[root@Clay ~]# free -m              total        used        free      shared  buff/cache   availableMem:           7821         801        6382           0         637        6719Swap:             0           0           0[root@Clay ~]# \n使用top命令查看系统负载 : \n[root@Clay ~]# toptop - 20:34:49 up 4 days,  1:00,  1 user,  load average: 0.13, 0.05, 0.05Tasks:  97 total,   1 running,  96 sleeping,   0 stopped,   0 zombie%Cpu(s):  0.2 us,  0.3 sy,  0.0 ni, 99.6 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 stKiB Mem :  8008876 total,  6535356 free,   820704 used,   652816 buff/cacheKiB Swap:        0 total,        0 free,        0 used.  6880284 avail Mem   PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND     1861 root      10 -10  131856  16248  10604 S   2.7  0.2 131:33.99 AliYunDun   1381 root      20   0   42296   4364   2876 S   0.7  0.1   2:36.14 AliYunDunU+   22 root      rt   0       0      0      0 S   0.3  0.0   0:00.53 watchdog/3  2118 root      10 -10  436912   2792   2320 S   0.3  0.0   1:45.12 AliSecGuard    1 root      20   0  190976   3936   2608 S   0.0  0.0   0:16.59 systemd        2 root      20   0       0      0      0 S   0.0  0.0   0:00.00 kthreadd       3 root      20   0       0      0      0 S   0.0  0.0   0:00.05 ksoftirqd/0    5 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/0:+    6 root      20   0       0      0      0 S   0.0  0.0   0:00.17 kworker/u8+    7 root      rt   0       0      0      0 S   0.0  0.0   0:00.01 migration/0    8 root      20   0       0      0      0 S   0.0  0.0   0:00.00 rcu_bh         9 root      20   0       0      0      0 S   0.0  0.0   0:41.92 rcu_sched     10 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 lru-add-dr+   11 root      rt   0       0      0      0 S   0.0  0.0   0:00.96 watchdog/0    12 root      rt   0       0      0      0 S   0.0  0.0   0:00.51 watchdog/1    13 root      rt   0       0      0      0 S   0.0  0.0   0:00.02 migration/1   14 root      20   0       0      0      0 S   0.0  0.0   0:00.01 ksoftirqd/1\n查看系统负载的命令是实时更新的，按Ctrl + c退出。\n查看系统进程使用ps -ef查看系统进程，在使用是可以搭配管道符|来过滤想要查看的具体服务进程。\nClay:mysqladmin:/usr/local/mysql:&gt;ps -ef | grep mysqlmysqlad+  2128     1  0 Nov13 ?        00:00:00 /bin/sh /usr/local/mysql/bin/mysqld_safemysqlad+  2783  2128  0 Nov13 ?        00:02:48 /usr/local/mysql/bin/mysqld --basedir=/usr/local/mysql --datadir=/usr/local/mysql/data --plugin-dir=/usr/local/mysql/lib/plugin --log-error=/usr/local/mysql/data/hostname.err --pid-file=/usr/local/mysql/data/hostname.pid --socket=/usr/local/mysql/data/mysql.sock --port=3306root     14023 12185  0 20:43 pts/1    00:00:00 su - mysqladminmysqlad+ 14024 14023  0 20:43 pts/1    00:00:00 -bashmysqlad+ 14060 14024  0 20:44 pts/1    00:00:00 ps -efmysqlad+ 14061 14024  0 20:44 pts/1    00:00:00 grep --color=auto mysqlClay:mysqladmin:/usr/local/mysql:&gt;\n进程名后的数字为服务的PID, 第一组为此进程的PID, 第二组为父进程的PID, 数字1表示为系统进程。\n查询到进程的PID后可以使用kill -9 + PID强制结束该进程。\n网络相关查询IP地址使用ifconfig, 系统会在终端展示出网卡的相关信息。使用ping + IP地址来查看网络是否畅通。可以通过PID来查询服务是运行在哪个端口上的, 查询端口的命令为netstat -nlp : \nClay:mysqladmin:/usr/local/mysql:&gt;netstat -nlp | grep 2783(Not all processes could be identified, non-owned process info will not be shown, you would have to be root to see it all.)tcp6       0      0 :::3306                 :::*                    LISTEN     2783/mysqld         unix  2      [ ACC ]     STREAM     LISTENING     25101    2783/mysqld          /usr/local/mysql/data/mysql.sockClay:mysqladmin:/usr/local/mysql:&gt;\n可以看到mysqld服务是运行在3306端口。查询服务器的某个端口是否畅通可以使用telnet ip 端口号命令查询。\n权限相关在使用ll命令查看详细信息的时候会在前面出现一组字母和数字。这些字母和数字就代表了权限内容。\n\n\n\n权限\n字母\n数字\n\n\n\n读\nr\n4\n\n\n写\nw\n2\n\n\n执\nx\n1\n\n\n无权限\n-\n0\n\n\n例子：\n\n\n\n\n[root@Clay ~]# lltotal 4-rw-r--r-- 1 root root 1 Nov 17 20:09 clay.log[root@Clay ~]# \n第一位的字符串表示文件类型 : \n\n\n\n符号\n意义\n\n\n\n-\n表示普通文件\n\n\nd\n表示目录文件\n\n\nl\n表示软连接\n\n\n后面的字符三个为一组, 如clay.log文件的权限可以分为rw-、r--和r--三组。三组权限标识的含义为 : \n\n\n\n权限标识\n含义\n\n\n\nrw-\n表示文件所有者(u)的权限，这里的用户为root用户。所以root用户对文件可读可写不可执\n\n\nr–\n表示所属组(g)的权限，这里的用户组为root。所以表示root用户组对该文件可读不可写不可执\n\n\nr–\n表示其他用户组的所有用户(o)对该文件的权限。所以表示其他用户组对该文件可读不可写不可执\n\n\n权限是可以修改的，在linux中可以使用chmod命令来修改权限。chmod -R 777 文件/文件夹这条命令可以修改文件或文件夹为任意用户、用户组都有可读可写可执权限。单独赋予某个权限可以使用chmod 用户(u/g/o)+权限字符 文件/文件夹, 例如想要给clay.log加上可执权限 :\n[root@Clay ~]# chmod u+x clay.log [root@Clay ~]# lltotal 4-rwxr--r-- 1 root root 1 Nov 17 20:09 clay.log\n如果想要给root组的其他用户也赋予可写权限, 可以执行下面的命令 :\n[root@Clay ~]# chmod g+w clay.log [root@Clay ~]# lltotal 4-rwxrw-r-- 1 root root 1 Nov 17 20:09 clay.log\n取消权限的命令把+替换为-即可。除了修改文件/文件夹权限外，还可以通过修改所属来达到变更权限的目的。修改所属使用chown命令，chown -R 用户:用户组 文件夹/目录, 参数-R是以递归的方式修改目录的所属。在生产中通常遇到的Permission Denied都是由权限不足导致的，可以通过修改权限解决。关于权限的问题更加详细的内容可以查看这篇博客。\n临时获得root权限在/etc/sudoers文件中配置中加入想要获取root权限的用户 :\n## Allow root to run any commands anywhereroot    ALL=(ALL)       ALLclay    ALL=(root)      NOPASSWORD=ALL\n保存退出后，clay用户就可以不输入root用户密码的情况下使用sudo暂时获得root权限。\n解压 &amp; 压缩对于后缀为tar.gz的文件可以使用tar来执行解压 : \ntar -zxvf xxx.tar.gz : 解压到当前路径下tar -zxvf xxx.tar.gz -C path : 解压到指定路径下\n压缩的指令为 : \ntar -cvzf xxx.tar.gz 需要压缩的文件(如果是目录可以使用目录/*批量压缩)\n如果是zip压缩包，则使用 : \nunzip xxx.zip : 解压到当前目录unzip -d path xxx.zip : 解压到指定路径\n打包压缩 : \nzip xxx.zip 源文件如果需要压缩一个目录时需要添加 -r参数zip -r xxx.zip 目录\n获取帮助如果在使用一个命令是不知道命令后面有什么参数的时候可以使用命令 --help来查看命令帮助。也可以使用man 命令来查看。\n","categories":["Linux"],"tags":["Linux"]},{"title":"MySQL部署","url":"/2021/11/15/Mysql-depoly/","content":"MySQL的部署方式MySQL可以使用官方二进制包进行部署，也可以使用rpm进行部署。两种方式都有各自的优缺点。\n使用二进制包部署的的优缺点：\n\n优点：可以定制化MySQL的目录\n缺点：部署较为繁琐\n\n使用rpm部署的优缺点：\n\n优点：部署简单。\n缺点：MySQL目录不能进行定制化。\n\n这里我们选择使用二进制包进行MySQL的部署。\n环境准备系统：CentOS 7\nMySQL版本：5.6.23\nJDK版本：1.8.0_311\nMySQL部署步骤部署前先确认服务器没有部署MySQL。[root@Clay local]# ps -ef | grep mysqldroot      1369 31888  0 19:56 pts/1    00:00:00 grep --color=auto mysqld[root@Clay local]# rpm -qa | grep -i mysql[root@Clay local]# \n\n解压二进制包[root@Clay local]$ tar -zxvf mysql-5.6.23-linux-glibc2.5-x86_64.tar.gz# 创建软连接[root@Clay local]$ ln -s mysql-5.6.23-linux-glibc2.5-x86_64 mysql\n\n创建用户组及用户创建一个dba用户组和mysqladmin用户。\n[root@Clay ~]$ groupadd -g 101 dba[root@Clay ~]$ useradd -u 514 -g dba -G root -d /usr/local/mysql mysqladmin[root@Clay ~]$ id mysqladminuid=514(mysqladmin) gid=101(dba) groups=101(dba),0(root)\n\n如果有如下提示：\n\nuseradd: warning: the home directory already exists.Not copying any file from skel directory into it.\n\n使用cp /etc/skel/.* /usr/local/mysql将配置文件拷贝到用户mysqladmin的家目录中。（如果不拷贝配置文件，切换到mysqladmin用户是界面会不正常。）\n创建MySQL配置文件[root@Clay ~]$ cd /etc/[root@Clay etc]$ vi my.cnf\n\n在新建的my.cnf文件中添加下面的配置：\n[client]port            = 3306socket          = /usr/local/mysql/data/mysql.sock [mysqld]port            = 3306socket          = /usr/local/mysql/data/mysql.sockskip-external-lockingkey_buffer_size = 256Msort_buffer_size = 2Mread_buffer_size = 2Mread_rnd_buffer_size = 4Mquery_cache_size= 32Mmax_allowed_packet = 16Mmyisam_sort_buffer_size=128Mtmp_table_size=32Mtable_open_cache = 512thread_cache_size = 8wait_timeout = 86400interactive_timeout = 86400max_connections = 600# Try number of CPU&#x27;s*2 for thread_concurrencythread_concurrency = 32#isolation level and default engine default-storage-engine = INNODBtransaction-isolation = READ-COMMITTEDserver-id  = 1basedir     = /usr/local/mysqldatadir     = /usr/local/mysql/datapid-file     = /usr/local/mysql/data/hostname.pid#open performance schemalog-warningssysdate-is-nowbinlog_format = MIXEDlog_bin_trust_function_creators=1log-error  = /usr/local/mysql/data/hostname.errlog-bin=/usr/local/mysql/arch/mysql-bin#other logs#general_log =1#general_log_file  = /usr/local/mysql/data/general_log.err#slow_query_log=1#slow_query_log_file=/usr/local/mysql/data/slow_log.err#for replication slave#log-slave-updates #sync_binlog = 1#for innodb options innodb_data_home_dir = /usr/local/mysql/data/innodb_data_file_path = ibdata1:500M:autoextendinnodb_log_group_home_dir = /usr/local/mysql/archinnodb_log_files_in_group = 2innodb_log_file_size = 200Minnodb_buffer_pool_size = 2048Minnodb_additional_mem_pool_size = 50Minnodb_log_buffer_size = 16Minnodb_lock_wait_timeout = 100#innodb_thread_concurrency = 0innodb_flush_log_at_trx_commit = 1innodb_locks_unsafe_for_binlog=1#innodb io features: add for mysql5.5.8performance_schemainnodb_read_io_threads=4innodb-write-io-threads=4innodb-io-capacity=200#purge threads change default(0) to 1 for purgeinnodb_purge_threads=1innodb_use_native_aio=on#case-sensitive file names and separate tablespaceinnodb_file_per_table = 1lower_case_table_names=1[mysqldump]quickmax_allowed_packet = 16M[mysql]no-auto-rehash[mysqlhotcopy]interactive-timeout[myisamchk]key_buffer_size = 256Msort_buffer_size = 256Mread_buffer = 2Mwrite_buffer = 2M\n\n几个需要调优的参数：\n\nlog-bin=/usr/local/mysql/arch/mysql-bin\ninnodb_log_file_size = 200M\ninnodb_buffer_pool_size = 2048M\n\n权限相关配置文件修改完成后需要对MySQL进行一些权限上的配置：\n[root@Clay ~]$ chown -R mysqladmin:dba /usr/local/mysql[root@Clay ~]$ chmod -R 755 /usr/local/mysql\n\n初始化MySQL初始化之前先切换到mysqladmin用户：\n[root@Clay local]# su - mysqladmin[mysqladmin@Clay ~]$ pwd/usr/local/mysql\n\npwd命令查看当前工作目录，并在当前目录创建：\n[mysqladmin@Clay ~]$ mkdir arch backup\n\n初始化MySQL：\n# \\表示换行scripts/mysql_install_db  --user=mysqladmin \\--basedir=/usr/local/mysql \\--datadir=/usr/local/mysql/data\n\n在初始化过程中可能会有报错，根据报错信息缺少什么就安装什么。\n配置MySQL服务并配置开机自启将服务文件拷贝到init.d下，并重新命名为mysql\n[root@Clay mysql-5.6.23-linux-glibc2.5-x86_64]$ cp support-files/mysql.server /etc/rc.d/init.d/mysql\n\n赋予可执行权限：\n[root@Clay mysql]$ chmod +x /etc/rc.d/init.d/mysql\n\n添加开机自启：\n# 先删除MySQL服务[root@Clay mysql]$ chkconfig --del mysql# 添加MySQL服务，并设置开机自启[root@Clay mysql]$ chkconfig --add mysql[root@Clay mysql]$ chkconfig --level 345 mysql on\n\n如果chkconfig --level 345 mysql on命令无效，在/etc/rc.local添加：\n\nsu - mysqladmin -c “/etc/init.d/mysql start –federated”\n\n启动MySQL，查看进程并监听切换到mysqladmin用户下进行：\n[root@Clay ~]$ su - mysqladmin# 因为前面的步骤已经在/etc下添加了定制化的my.cnf配置文件，所以要删除mysqladmin用户家目录下的my.cnf[mysqladmin@Clay ~]$ rm -rf my.cnf \n\n接下来将MySQL添加到mysqladmin用户的个人环境变量中：\n[mysqladmin@Clay ~]$ vi ~/.bashrcexport MYSQL_HOME=/usr/local/mysqlexport PATH=$MYSQL_HOME/bin:$PATH[mysqladmin@Clay ~]$ source ~/.bashrc\n\n配置完成后启动MySQL：\n[mysqladmin@Clay ~]$ mysqld_safe &amp;# 查看MySQL进程[mysqladmin@Clay ~]$ ps -ef|grep mysqldmysqlad+  7061  6633  0 21:41 pts/0    00:00:00 /bin/sh /usr/local/mysql/bin/mysqld_safemysqlad+  7838  7061  0 21:41 pts/0    00:00:00 /usr/local/mysql/bin/mysqld --basedir=/usr/local/mysql --datadir=/usr/local/mysql/data --plugin-dir=/usr/local/mysql/lib/plugin --log-error=/usr/local/mysql/data/hostname.err --pid-file=/usr/local/mysql/data/hostname.pid --socket=/usr/local/mysql/data/mysql.sock --port=3306# 查询MySQL服务状态[mysqladmin@Clay ~]$ service mysql statusMySQL running (7838)[  OK  ]\n\n登录MySQL服务正常，登录MySQL：\n[mysqladmin@Clay ~]$ mysql -urootWelcome to the MySQL monitor.  Commands end with ; or \\g.Your MySQL connection id is 1Server version: 5.6.23-log MySQL Community Server (GPL)Copyright (c) 2000, 2015, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type &#x27;help;&#x27; or &#x27;\\h&#x27; for help. Type &#x27;\\c&#x27; to clear the current input statement.mysql&gt; \n\n查看MySQL默认数据库：\nmysql&gt; show databases;+--------------------+| Database           |+--------------------+| information_schema || mysql              || performance_schema || test               |+--------------------+4 rows in set (0.00 sec)\n\n正常为4个默认数据库，少于4个则安装错误。\n更新root用户密码：\n# 括号内的password为想要设置的密码，自行替换。mysql&gt; update user set password=password(&#x27;password&#x27;) where user=&#x27;root&#x27;;Query OK, 4 rows affected (0.00 sec)Rows matched: 4  Changed: 4  Warnings: 0# 在uesr表中查询mysql&gt; select host,user,password from user;+-----------+------+-------------------------------------------+| host      | user | password                                  |+-----------+------+-------------------------------------------+| localhost | root | *B01B5FDBF6FD75695911F146FAE7509B2BA216E0 || clay      | root | *B01B5FDBF6FD75695911F146FAE7509B2BA216E0 || 127.0.0.1 | root | *B01B5FDBF6FD75695911F146FAE7509B2BA216E0 || ::1       | root | *B01B5FDBF6FD75695911F146FAE7509B2BA216E0 || localhost |      |                                           || clay      |      |                                           |+-----------+------+-------------------------------------------+6 rows in set (0.00 sec)# 删除用户为空的数据mysql&gt; delete from user where user=&#x27;&#x27;;Query OK, 2 rows affected (0.00 sec)mysql&gt; select host,user,password from user;+-----------+------+-------------------------------------------+| host      | user | password                                  |+-----------+------+-------------------------------------------+| localhost | root | *B01B5FDBF6FD75695911F146FAE7509B2BA216E0 || clay      | root | *B01B5FDBF6FD75695911F146FAE7509B2BA216E0 || 127.0.0.1 | root | *B01B5FDBF6FD75695911F146FAE7509B2BA216E0 || ::1       | root | *B01B5FDBF6FD75695911F146FAE7509B2BA216E0 |+-----------+------+-------------------------------------------+4 rows in set (0.00 sec)# 更新密码后要记得刷新权限mysql&gt; flush privileges;Query OK, 0 rows affected (0.00 sec)\n\nMySQL损坏，如何处理先删除binlog文件：\nrm -rf $MYSQL_HOME/arch/*\n\n删除数据文件：\nrm -rf $MYSQL_HOME/data/*\n\n然后初始化MySQL：\nscripts/mysql_install_db  --user=mysqladmin \\--basedir=/usr/local/mysql \\--datadir=/usr/local/mysql/data\n\nMac连接DBeaverDBeaver是一款开源的通用数据库管理和开发工具。连接前要在服务器做一些准备：\n# 先安装httpdyum install -y httpd# 安装后启动httpd服务service httpd start# 启动之后查看httpd服务状态service httpd status\n\n由于服务器是阿里云的云主机。在连接之前先要到阿里云的安全组开放80端口。否则连接会失败。准备工作做完，连接Dbeaver可以参考这篇博客 中Windows平台的连接方式。\nTips：在/etc/hosts文件中加入服务器的映射名是很有必要的。首先排除了服务器IP暴露的风险。其次在迁移时只需要修改hosts文件中的映射即可，不需要逐个修改配置文件。\n","categories":["MySQL"],"tags":["MySQL"]},{"title":"Spark源码编译","url":"/2019/10/13/Spark-compile/","content":"Spark源码编译环境：Mac OS 10.15；jdk 1.8；Spark-2.3.0；Maven-3.3.9。准备好环境以后，在Spark-2.3.0文件目录下运行\n./dev/make-distribution.sh --name 2.6.0-cdh5.7.0 --tgz -Pyarn -Phadoop-2.6 -Phive -Phive-thriftserver -Dhadoop.version=2.6.0-cdh5.7.0\n由于使用的是cdh版本的hadoop2.6.0，导致在编译时会出现错误：\n[ERROR] Failed to execute goal on project spark-launcher_2.11: Could not resolve dependencies for project org.apache.spark:spark-launcher_2.11:jar:2.3.0: Failure to find org.apache.hadoop:hadoop-client:jar:2.6.0-cdh5.7.0 in https://repo1.maven.org/maven2 was cached in the local repository, resolution will not be reattempted until the update interval of central has elapsed or updates are forced -&gt; [Help 1][ERROR] [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.[ERROR] Re-run Maven using the -X switch to enable full debug logging.[ERROR] [ERROR] For more information about the errors and possible solutions, please read the following articles:[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/DependencyResolutionException[ERROR] [ERROR] After correcting the problems, you can resume the build with the command[ERROR]   mvn &lt;goals&gt; -rf :spark-launcher_2.11\n在编译时会找不到包而导致编译失败。因为Spark默认的数据源是Apache，而在编译时使用的是cdh版本的hadoop。所以要在pom.xml文件中修改数据源。\n&lt;repositories&gt;    &lt;repository&gt;      &lt;id&gt;central&lt;/id&gt;      &lt;!-- This should be at top, it makes maven try the central repo first and then others and hence faster dep resolution --&gt;      &lt;name&gt;Maven Repository&lt;/name&gt;      &lt;url&gt;https://repo.maven.apache.org/maven2&lt;/url&gt;      &lt;releases&gt;        &lt;enabled&gt;true&lt;/enabled&gt;      &lt;/releases&gt;      &lt;snapshots&gt;        &lt;enabled&gt;false&lt;/enabled&gt;      &lt;/snapshots&gt;    &lt;/repository&gt;-----------------------------------------------------------------------------------------    &lt;repository&gt;      &lt;id&gt;cloudera&lt;/id&gt;      &lt;name&gt;cloudera Repository&lt;/name&gt;      &lt;url&gt;https://repository.cloudera.com/artifactory/cloudera-repos&lt;/url&gt;   &lt;/repository&gt;-----------------------------------------------------------------------------------------  &lt;/repositories&gt;\n在Spark的pom.xml文件中添加两横线中间的内容，将cloudera数据源添加进去。之后再按照Spark官网给出的编译指南进行编译即可。\n","categories":["Spark"],"tags":["Spark"]},{"title":"HDFS常用的shell操作指令","url":"/2021/12/01/hadoop-shell/","content":"Hadoop常用的shell命令这篇博客只记录、操作一些常用的命令，关于Hadoop的shell命令可以参考官方的Documentation 里更加详细的解释。HDFS系统的shell指令与Linux的指令十分相似，指令所实现的功能也大致相同。\nls &amp; lsr查看HDFS文件系统中的文件、文件夹信息，HDFS中没有ls -l的指令。ls指令所展示的即详细信息。\n[clay@Clay hadoop]$ hdfs dfs -ls /Found 4 itemsdrwxr-xr-x   - clay supergroup          0 2021-11-29 22:33 /inputdrwxr-xr-x   - clay supergroup          0 2021-11-29 23:35 /outputdrwx------   - clay supergroup          0 2021-11-29 22:11 /tmpdrwxr-xr-x   - clay supergroup          0 2021-11-29 22:10 /user\n\n如上指令，执行之后显示了权限、所属用户、用户组等信息。\nlsr指令是以递归的方式显示信息：\n[clay@Clay ~]$ hdfs dfs -lsr /userlsr: DEPRECATED: Please use &#x27;ls -R&#x27; instead.drwxr-xr-x   - clay supergroup          0 2021-11-30 22:06 /user/claydrwxr-xr-x   - clay supergroup          0 2021-11-29 22:11 /user/clay/input-rw-r--r--   1 clay supergroup       9213 2021-11-29 22:11 /user/clay/input/capacity-scheduler.xml-rw-r--r--   1 clay supergroup        349 2021-11-29 22:11 /user/clay/input/core-site.xml-rw-r--r--   1 clay supergroup      11392 2021-11-29 22:11 /user/clay/input/hadoop-policy.xml-rw-r--r--   1 clay supergroup        459 2021-11-29 22:11 /user/clay/input/hdfs-site.xml-rw-r--r--   1 clay supergroup        620 2021-11-29 22:11 /user/clay/input/httpfs-site.xml-rw-r--r--   1 clay supergroup       3518 2021-11-29 22:11 /user/clay/input/kms-acls.xml-rw-r--r--   1 clay supergroup        682 2021-11-29 22:11 /user/clay/input/kms-site.xml-rw-r--r--   1 clay supergroup        483 2021-11-29 22:11 /user/clay/input/mapred-site.xml-rw-r--r--   1 clay supergroup        586 2021-11-29 22:11 /user/clay/input/yarn-site.xmldrwxr-xr-x   - clay supergroup          0 2021-11-30 22:06 /user/clay/testdrwxr-xr-x   - clay supergroup          0 2021-11-30 22:06 /user/clay/test/1drwxr-xr-x   - clay supergroup          0 2021-11-30 22:06 /user/clay/test/1/2\n\n可以看到显示结果中提示lsr命令已弃用，由ls -R代替。\n-ls后还可以添加其他参数，参数列表及参数实现的功能如下：\n\n-C: Display the paths of files and directories only.\n-d: Directories are listed as plain files.\n-h: Format file sizes in a human-readable fashion (eg 64.0m instead of 67108864).\n-q: Print ? instead of non-printable characters.\n-R: Recursively list subdirectories encountered.\n-t: Sort output by modification time (most recent first).\n-S: Sort output by file size.\n-r: Reverse the sort order.\n-u: Use access time rather than modification time for display and sorting.\n-e: Display the erasure coding policy of files and directories only.\n\ncat与Linux相同，是用来查看文件的内容。\n[clay@Clay ~]$ hdfs dfs -ls /inputFound 1 items-rw-r--r--   1 clay supergroup         45 2021-11-29 22:33 /input/1.log[clay@Clay ~]$ hdfs dfs -cat /input/1.logclayclayhello worda s d fs a f dd f a s\n\nmkdir创建一个目录。同样可以使用-p参数来级联创建目录。\n[clay@Clay ~]$ hdfs dfs -mkdir -p /test/1/2[clay@Clay ~]$ hdfs dfs -ls -R /testdrwxr-xr-x   - clay supergroup          0 2021-11-30 22:06 /test/1drwxr-xr-x   - clay supergroup          0 2021-11-30 22:06 /test/1/2\n\n同样可以并联创建目录：\n[clay@Clay ~]$ hdfs dfs -mkdir /test1 /test2[clay@Clay ~]$ hdfs dfs -ls /Found 7 itemsdrwxr-xr-x   - clay supergroup          0 2021-11-29 22:33 /inputdrwxr-xr-x   - clay supergroup          0 2021-11-29 23:35 /outputdrwxr-xr-x   - clay supergroup          0 2021-11-30 22:06 /testdrwxr-xr-x   - clay supergroup          0 2021-11-30 22:12 /test1drwxr-xr-x   - clay supergroup          0 2021-11-30 22:12 /test2drwx------   - clay supergroup          0 2021-11-29 22:11 /tmpdrwxr-xr-x   - clay supergroup          0 2021-11-29 22:10 /user\n\ntouch &amp; touchztouch和touchz命令相似，但是touch命令有更多的可选参数而touchz没有可选参数。\n[clay@Clay ~]$ hdfs dfs -touch /test/test.log[clay@Clay ~]$ hdfs dfs -ls /testFound 2 itemsdrwxr-xr-x   - clay supergroup          0 2021-11-30 22:06 /test/1-rw-r--r--   1 clay supergroup          0 2021-11-30 22:20 /test/test.log\n\ntouch创建的是一个长度为0的空文件。\ntouchz的功能是创建一个空文件，如果存在一个同名的非空文件会返回error。\n[clay@Clay ~]$ hdfs dfs -ls /inputFound 1 items-rw-r--r--   1 clay supergroup         45 2021-11-29 22:33 /input/1.log[clay@Clay ~]$ hdfs dfs -cat /input/1.logclayclayhello worda s d fs a f dd f a s[clay@Clay ~]$ hdfs dfs -touchz /input/1.logtouchz: `/input/1.log&#x27;: Not a zero-length file\n\nmv-mv命令实现的功能与Linux一致，可以移动移动文件到另一个目录中。但是不能在不同文件系统之间移动。\n# 移动单个文件到指定目录[clay@Clay ~]$ hdfs dfs -ls /testFound 2 itemsdrwxr-xr-x   - clay supergroup          0 2021-11-30 22:06 /test/1-rw-r--r--   1 clay supergroup          0 2021-11-30 22:20 /test/test.log[clay@Clay ~]$ hdfs dfs -mv /test1/file.log /test[clay@Clay ~]$ hdfs dfs -ls /testFound 3 itemsdrwxr-xr-x   - clay supergroup          0 2021-11-30 22:06 /test/1-rw-r--r--   1 clay supergroup          0 2021-12-01 20:31 /test/file.log-rw-r--r--   1 clay supergroup          0 2021-11-30 22:20 /test/test.log# 移动多个文件到指定的目录[clay@Clay ~]$ hdfs dfs -ls /testFound 3 itemsdrwxr-xr-x   - clay supergroup          0 2021-11-30 22:06 /test/1-rw-r--r--   1 clay supergroup          0 2021-12-01 20:31 /test/file.log-rw-r--r--   1 clay supergroup          0 2021-11-30 22:20 /test/test.log[clay@Clay ~]$ hdfs dfs -ls /test1Found 2 items-rw-r--r--   1 clay supergroup          0 2021-12-01 20:35 /test1/file1.log-rw-r--r--   1 clay supergroup          0 2021-12-01 20:31 /test1/file2.log[clay@Clay ~]$ hdfs dfs -mv /test1/file1.log /test1/file2.log /test[clay@Clay ~]$ hdfs dfs -ls /testFound 5 itemsdrwxr-xr-x   - clay supergroup          0 2021-11-30 22:06 /test/1-rw-r--r--   1 clay supergroup          0 2021-12-01 20:31 /test/file.log-rw-r--r--   1 clay supergroup          0 2021-12-01 20:35 /test/file1.log-rw-r--r--   1 clay supergroup          0 2021-12-01 20:31 /test/file2.log-rw-r--r--   1 clay supergroup          0 2021-11-30 22:20 /test/test.log\n\nput &amp; moveFromLocal &amp; copyFromLocal三个命令的功能都是将文件从本地上传到文件系统中。put命令有更多的可选参数：\n\n\n-p : Preserves access and modification times, ownership and the permissions. (assuming the permissions can be propagated across filesystems)\n-f : Overwrites the destination if it already exists.\n-t &lt;thread count&gt; : Number of threads to be used, default is 1. Useful when uploading a directory containing more than 1 file.\n-l : Allow DataNode to lazily persist the file to disk, Forces a replication factor of 1. This flag will result in reduced durability. Use with care.\n-d : Skip creation of temporary file with the suffix ._COPYING_.\n\n\n[clay@Clay ~]$ lltotal 28drwxrwxr-x 3 clay clay 4096 Nov 22 21:20 appdrwxrwxr-x 2 clay clay 4096 Nov 22 21:05 data-rw-rw-r-- 1 clay clay    0 Dec  1 20:58 file3.logdrwxrwxr-x 2 clay clay 4096 Nov 22 21:05 libdrwxrwxr-x 2 clay clay 4096 Nov 22 21:05 logdrwxrwxr-x 2 clay clay 4096 Nov 22 21:11 softwaredrwxrwxr-x 2 clay clay 4096 Nov 22 21:05 sourcecodedrwxrwxr-x 3 clay clay 4096 Nov 30 20:44 tmp[clay@Clay ~]$ hdfs dfs -put file3.log /test[clay@Clay ~]$ hdfs dfs -ls /testFound 6 itemsdrwxr-xr-x   - clay supergroup          0 2021-11-30 22:06 /test/1-rw-r--r--   1 clay supergroup          0 2021-12-01 20:31 /test/file.log-rw-r--r--   1 clay supergroup          0 2021-12-01 20:35 /test/file1.log-rw-r--r--   1 clay supergroup          0 2021-12-01 20:31 /test/file2.log-rw-r--r--   1 clay supergroup          0 2021-12-01 20:59 /test/file3.log-rw-r--r--   1 clay supergroup          0 2021-11-30 22:20 /test/test.log\n\n而moveFromLocal没有可选的参数，并且会在上传完成后删除源文件。\n[clay@Clay ~]$ lltotal 28drwxrwxr-x 3 clay clay 4096 Nov 22 21:20 appdrwxrwxr-x 2 clay clay 4096 Nov 22 21:05 data-rw-rw-r-- 1 clay clay    0 Dec  1 20:58 file3.logdrwxrwxr-x 2 clay clay 4096 Nov 22 21:05 libdrwxrwxr-x 2 clay clay 4096 Nov 22 21:05 logdrwxrwxr-x 2 clay clay 4096 Nov 22 21:11 softwaredrwxrwxr-x 2 clay clay 4096 Nov 22 21:05 sourcecodedrwxrwxr-x 3 clay clay 4096 Nov 30 20:44 tmp[clay@Clay ~]$ hdfs dfs -put file3.log /test[clay@Clay ~]$ hdfs dfs -ls /testFound 6 itemsdrwxr-xr-x   - clay supergroup          0 2021-11-30 22:06 /test/1-rw-r--r--   1 clay supergroup          0 2021-12-01 20:31 /test/file.log-rw-r--r--   1 clay supergroup          0 2021-12-01 20:35 /test/file1.log-rw-r--r--   1 clay supergroup          0 2021-12-01 20:31 /test/file2.log-rw-r--r--   1 clay supergroup          0 2021-12-01 20:59 /test/file3.log-rw-r--r--   1 clay supergroup          0 2021-11-30 22:20 /test/test.log[clay@Clay ~]$ hdfs dfs -moveFromLocal file3.log /test1[clay@Clay ~]$ hdfs dfs -ls /test1Found 1 items-rw-r--r--   1 clay supergroup          0 2021-12-01 21:05 /test1/file3.log[clay@Clay ~]$ ll # 本地目录的file3.log已经被删除了total 28drwxrwxr-x 3 clay clay 4096 Nov 22 21:20 appdrwxrwxr-x 2 clay clay 4096 Nov 22 21:05 datadrwxrwxr-x 2 clay clay 4096 Nov 22 21:05 libdrwxrwxr-x 2 clay clay 4096 Nov 22 21:05 logdrwxrwxr-x 2 clay clay 4096 Nov 22 21:11 softwaredrwxrwxr-x 2 clay clay 4096 Nov 22 21:05 sourcecodedrwxrwxr-x 3 clay clay 4096 Nov 30 20:44 tmp\n\ncopyFromLocal与put相同，两者没有区别，也不会删除源文件。\n[clay@Clay ~]$ hdfs dfs -copyFromLocal test.log /test[clay@Clay ~]$ hdfs dfs -ls /testFound 6 itemsdrwxr-xr-x   - clay supergroup          0 2021-11-30 22:06 /test/1-rw-r--r--   1 clay supergroup          0 2021-12-01 20:31 /test/file.log-rw-r--r--   1 clay supergroup          0 2021-12-01 20:35 /test/file1.log-rw-r--r--   1 clay supergroup          0 2021-12-01 20:31 /test/file2.log-rw-r--r--   1 clay supergroup          0 2021-12-01 20:59 /test/file3.log-rw-r--r--   1 clay supergroup          0 2021-12-01 21:49 /test/test.log\n\n\n\nget &amp; moveToLocal &amp; copyToLocal三个命令功能相同，都是从文件系统拷贝到本地文件系统。但是get有更多的可选参数：\n\n\n-p : Preserves access and modification times, ownership and the permissions. (assuming the permissions can be propagated across filesystems)\n-f : Overwrites the destination if it already exists.\n-ignorecrc : Skip CRC checks on the file(s) downloaded.\n-crc: write CRC checksums for the files downloaded.\n\n\n[clay@Clay ~]$ hdfs dfs -ls /testFound 6 itemsdrwxr-xr-x   - clay supergroup          0 2021-11-30 22:06 /test/1-rw-r--r--   1 clay supergroup          0 2021-12-01 20:31 /test/file.log-rw-r--r--   1 clay supergroup          0 2021-12-01 20:35 /test/file1.log-rw-r--r--   1 clay supergroup          0 2021-12-01 20:31 /test/file2.log-rw-r--r--   1 clay supergroup          0 2021-12-01 20:59 /test/file3.log-rw-r--r--   1 clay supergroup          0 2021-11-30 22:20 /test/test.log[clay@Clay ~]$ hdfs dfs -get /test/test.log /home/clay[clay@Clay ~]$ lltotal 28drwxrwxr-x 3 clay clay 4096 Nov 22 21:20 appdrwxrwxr-x 2 clay clay 4096 Nov 22 21:05 datadrwxrwxr-x 2 clay clay 4096 Nov 22 21:05 libdrwxrwxr-x 2 clay clay 4096 Nov 22 21:05 logdrwxrwxr-x 2 clay clay 4096 Nov 22 21:11 softwaredrwxrwxr-x 2 clay clay 4096 Nov 22 21:05 sourcecode-rw-r--r-- 1 clay clay    0 Dec  1 21:16 test.logdrwxrwxr-x 3 clay clay 4096 Nov 30 20:44 tmp\n\nmvToLocal实现相同功能，但是现在官方并没有实现这个功能。copyToLocal与get相同，不会对源文件产生影响。\n[clay@Clay ~]$ lltotal 28drwxrwxr-x 3 clay clay 4096 Nov 22 21:20 appdrwxrwxr-x 2 clay clay 4096 Nov 22 21:05 datadrwxrwxr-x 2 clay clay 4096 Nov 22 21:05 libdrwxrwxr-x 2 clay clay 4096 Nov 22 21:05 logdrwxrwxr-x 2 clay clay 4096 Nov 22 21:11 softwaredrwxrwxr-x 2 clay clay 4096 Nov 22 21:05 sourcecodedrwxrwxr-x 3 clay clay 4096 Nov 30 20:44 tmp[clay@Clay ~]$ hdfs dfs -copyToLocal /test/test.log /home/clay[clay@Clay ~]$ lltotal 28drwxrwxr-x 3 clay clay 4096 Nov 22 21:20 appdrwxrwxr-x 2 clay clay 4096 Nov 22 21:05 datadrwxrwxr-x 2 clay clay 4096 Nov 22 21:05 libdrwxrwxr-x 2 clay clay 4096 Nov 22 21:05 logdrwxrwxr-x 2 clay clay 4096 Nov 22 21:11 softwaredrwxrwxr-x 2 clay clay 4096 Nov 22 21:05 sourcecode-rw-r--r-- 1 clay clay    0 Dec  1 21:52 test.logdrwxrwxr-x 3 clay clay 4096 Nov 30 20:44 tmp\n\ncp拷贝命令，可以有多个源文件，但是目标必须是一个目录才可以。\n[clay@Clay ~]$ hdfs dfs -ls /test1Found 1 items-rw-r--r--   1 clay supergroup          0 2021-12-01 21:05 /test1/file3.log[clay@Clay ~]$ hdfs dfs -cp /test/file2.log /test1[clay@Clay ~]$ hdfs dfs -ls /test1Found 2 items-rw-r--r--   1 clay supergroup          0 2021-12-01 21:55 /test1/file2.log-rw-r--r--   1 clay supergroup          0 2021-12-01 21:05 /test1/file3.log\n\n可以同时拷贝多个文件到指定目录：\n[clay@Clay ~]$ hdfs dfs -cp /test/file.log /test/file1.log /test1[clay@Clay ~]$ hdfs dfs -ls /test1Found 4 items-rw-r--r--   1 clay supergroup          0 2021-12-01 21:57 /test1/file.log-rw-r--r--   1 clay supergroup          0 2021-12-01 21:57 /test1/file1.log-rw-r--r--   1 clay supergroup          0 2021-12-01 21:55 /test1/file2.log-rw-r--r--   1 clay supergroup          0 2021-12-01 21:05 /test1/file3.log\n\ndf显示文件系统的空余空间。可选参数为-h，参数的作用就是将空间转化为人类易读的：\n# 不添加-h参数[clay@Clay ~]$ hdfs dfs -df /Filesystem               Size     Used    Available  Use%hdfs://Clay:9000  42135011328  4235264  33626238976    0%# 使用-h参数[clay@Clay ~]$ hdfs dfs -df -h /Filesystem          Size   Used  Available  Use%hdfs://Clay:9000  39.2 G  4.0 M     31.3 G    0%\n\ndu显示文件、文件夹的大小。可选参数为：\n\n\nThe -s option will result in an aggregate summary of file lengths being displayed, rather than the individual files. Without the -s option, calculation is done by going 1-level deep from the given path.\nThe -h option will format file sizes in a “human-readable” fashion (e.g 64.0m instead of 67108864)\nThe -v option will display the names of columns as a header line.\nThe -x option will exclude snapshots from the result calculation. Without the -x option (default), the result is always calculated from all INodes, including all snapshots under the given path.\n\n\n命令返回的三项数据为：\n\nsize disk_space_consumed_with_all_replicas full_path_name\n\n# 查看目录的大小[clay@Clay ~]$ hdfs dfs -du -h /45      45      /input38      38      /output0       0       /test0       0       /test10       0       /test23.7 M   22.7 M  /tmp26.7 K  26.7 K  /user# 查看文件的大小可以使用-s参数[clay@Clay ~]$ hdfs dfs -du -s -h /input/1.log45  45  /input/1.log[clay@Clay ~]$ hdfs dfs -du -s -h /user/clay/input/*9.0 K   9.0 K   /user/clay/input/capacity-scheduler.xml349     349     /user/clay/input/core-site.xml11.1 K  11.1 K  /user/clay/input/hadoop-policy.xml459     459     /user/clay/input/hdfs-site.xml620     620     /user/clay/input/httpfs-site.xml3.4 K   3.4 K   /user/clay/input/kms-acls.xml682     682     /user/clay/input/kms-site.xml483     483     /user/clay/input/mapred-site.xml586     586     /user/clay/input/yarn-site.xml\n\n官方文档中还提到了dus命令。但是dus已经被标识deprecated，由du -s代替。\ntail显示文件的最后千字节的内容，-f参数可以实现查看新增数据。\n[clay@Clay ~]$ hdfs dfs -tail /input/1.logclayclayhello worda s d fs a f dd f a s\n\nchmod &amp; chown可以修改权限和文件所属。-R参数可以实现以递归的方式修改目录下的文件的权限。\n[clay@Clay ~]$ hdfs dfs -ls /testFound 6 itemsdrwxr-xr-x   - clay supergroup          0 2021-11-30 22:06 /test/1-rw-r--r--   1 clay supergroup          0 2021-12-01 20:31 /test/file.log-rw-r--r--   1 clay supergroup          0 2021-12-01 20:35 /test/file1.log-rw-r--r--   1 clay supergroup          0 2021-12-01 20:31 /test/file2.log-rw-r--r--   1 clay supergroup          0 2021-12-01 20:59 /test/file3.log-rw-r--r--   1 clay supergroup          0 2021-12-01 21:49 /test/test.log[clay@Clay ~]$ hdfs dfs -chmod 666 /test/file.log[clay@Clay ~]$ hdfs dfs -ls /testFound 6 itemsdrwxr-xr-x   - clay supergroup          0 2021-11-30 22:06 /test/1-rw-rw-rw-   1 clay supergroup          0 2021-12-01 20:31 /test/file.log-rw-r--r--   1 clay supergroup          0 2021-12-01 20:35 /test/file1.log-rw-r--r--   1 clay supergroup          0 2021-12-01 20:31 /test/file2.log-rw-r--r--   1 clay supergroup          0 2021-12-01 20:59 /test/file3.log-rw-r--r--   1 clay supergroup          0 2021-12-01 21:49 /test/test.log# 使用-R参数修改所有log文件的权限[clay@Clay ~]$ hdfs dfs -chmod -R 666 /test[clay@Clay ~]$ hdfs dfs -ls /testFound 6 itemsdrw-rw-rw-   - clay supergroup          0 2021-11-30 22:06 /test/1-rw-rw-rw-   1 clay supergroup          0 2021-12-01 20:31 /test/file.log-rw-rw-rw-   1 clay supergroup          0 2021-12-01 20:35 /test/file1.log-rw-rw-rw-   1 clay supergroup          0 2021-12-01 20:31 /test/file2.log-rw-rw-rw-   1 clay supergroup          0 2021-12-01 20:59 /test/file3.log-rw-rw-rw-   1 clay supergroup          0 2021-12-01 21:49 /test/test.log\n\nrm &amp; rmdir删除功能，有可选参数：\n\n\nThe -f option will not display a diagnostic message or modify the exit status to reflect an error if the file does not exist.\nThe -R option deletes the directory and any content under it recursively.\nThe -r option is equivalent to -R.\nThe -skipTrash option will bypass trash, if enabled, and delete the specified file(s) immediately. This can be useful when it is necessary to delete files from an over-quota directory.\nThe -safely option will require safety confirmation before deleting directory with total number of files greater than hadoop.shell.delete.limit.num.files (in core-site.xml, default: 100). It can be used with -skipTrash to prevent accidental deletion of large directories. Delay is expected when walking over large directory recursively to count the number of files to be deleted before the confirmation.\n\n\n# 删除特定文件[clay@Clay ~]$ hdfs dfs -ls -R /testdrw-rw-rw-   - clay supergroup          0 2021-11-30 22:06 /test/1drw-rw-rw-   - clay supergroup          0 2021-11-30 22:06 /test/1/2-rw-rw-rw-   1 clay supergroup          0 2021-12-01 20:31 /test/file.log-rw-rw-rw-   1 clay supergroup          0 2021-12-01 20:35 /test/file1.log-rw-rw-rw-   1 clay supergroup          0 2021-12-01 20:31 /test/file2.log-rw-rw-rw-   1 clay supergroup          0 2021-12-01 20:59 /test/file3.log-rw-rw-rw-   1 clay supergroup          0 2021-12-01 21:49 /test/test.log[clay@Clay ~]$ hdfs dfs -rm /test/test.logDeleted /test/test.log[clay@Clay ~]$ hdfs dfs -ls -R /testdrw-rw-rw-   - clay supergroup          0 2021-11-30 22:06 /test/1drw-rw-rw-   - clay supergroup          0 2021-11-30 22:06 /test/1/2-rw-rw-rw-   1 clay supergroup          0 2021-12-01 20:31 /test/file.log-rw-rw-rw-   1 clay supergroup          0 2021-12-01 20:35 /test/file1.log-rw-rw-rw-   1 clay supergroup          0 2021-12-01 20:31 /test/file2.log-rw-rw-rw-   1 clay supergroup          0 2021-12-01 20:59 /test/file3.log\n\n# 使用-R参数[clay@Clay ~]$ hdfs dfs -rm -R /test/1Deleted /test/1[clay@Clay ~]$ hdfs dfs -ls -R /test-rw-rw-rw-   1 clay supergroup          0 2021-12-01 20:31 /test/file.log-rw-rw-rw-   1 clay supergroup          0 2021-12-01 20:35 /test/file1.log-rw-rw-rw-   1 clay supergroup          0 2021-12-01 20:31 /test/file2.log-rw-rw-rw-   1 clay supergroup          0 2021-12-01 20:59 /test/file3.log\n\nrmdir命令可以用来删除空目录，还有一个可选参数：\n\n--ignore-fail-on-non-empty: When using wildcards, do not fail if a directory still contains files.\n\n[clay@Clay ~]$ hdfs dfs -ls /test2[clay@Clay ~]$ hdfs dfs -rmdir /test2[clay@Clay ~]$ hdfs dfs -ls /Found 7 itemsdrwxr-xr-x   - clay supergroup          0 2021-12-01 23:28 /adrwxr-xr-x   - clay supergroup          0 2021-11-29 22:33 /inputdrwxr-xr-x   - clay supergroup          0 2021-11-29 23:35 /outputdrw-rw-rw-   - clay supergroup          0 2021-12-01 23:24 /testdrwxr-xr-x   - clay supergroup          0 2021-12-01 21:57 /test1drwx------   - clay supergroup          0 2021-11-29 22:11 /tmpdrwxr-xr-x   - clay supergroup          0 2021-11-29 22:10 /user\n\ntest2是一个空目录，使用rmdir可以直接删除。\n[clay@Clay ~]$ hdfs dfs -ls -R /testdrwxr-xr-x   - clay supergroup          0 2021-12-01 23:24 /test/adrwxr-xr-x   - clay supergroup          0 2021-12-01 23:24 /test/a/bdrwxr-xr-x   - clay supergroup          0 2021-12-01 23:24 /test/a/b/c-rw-rw-rw-   1 clay supergroup          0 2021-12-01 20:31 /test/file.log-rw-rw-rw-   1 clay supergroup          0 2021-12-01 20:35 /test/file1.log-rw-rw-rw-   1 clay supergroup          0 2021-12-01 20:31 /test/file2.log-rw-rw-rw-   1 clay supergroup          0 2021-12-01 20:59 /test/file3.log[clay@Clay ~]$ hdfs dfs -rmdir --ignore-fail-on-non-empty /test/a[clay@Clay ~]$ hdfs dfs -ls -R /testdrwxr-xr-x   - clay supergroup          0 2021-12-01 23:24 /test/adrwxr-xr-x   - clay supergroup          0 2021-12-01 23:24 /test/a/bdrwxr-xr-x   - clay supergroup          0 2021-12-01 23:24 /test/a/b/c-rw-rw-rw-   1 clay supergroup          0 2021-12-01 20:31 /test/file.log-rw-rw-rw-   1 clay supergroup          0 2021-12-01 20:35 /test/file1.log-rw-rw-rw-   1 clay supergroup          0 2021-12-01 20:31 /test/file2.log-rw-rw-rw-   1 clay supergroup          0 2021-12-01 20:59 /test/file3.log\n\n当目录不为空时，添加参数--ignore-fail-on-non-empty后既不报错也不删除目录。\n以上为常用的shell命令，官方文档 中有更加详细的命令集合、命令的详细功能及命令的可选参数解释。\n","categories":["Hadoop"],"tags":["Hadoop"]},{"title":"Hadoop安装与伪分布式部署","url":"/2021/11/27/hadoopdeploy/","content":"关于Hadoop广义上的Hadoop是指以Hadoop 软件为主的软件生态圈；狭义上的Hadoop则是指Hadoop软件本身。\nHadoop是由Apache基金会开发的一个分布式系统基础架构，也是Apache基金会的顶级项目之一。Hadoop可以充分利用集群的威力来进行高速运算和存储。Hadoop有三个核心组件：\n\nHDFS：分布式文件系统，主要的作用是用来存储数据。具有高容错、低成本、高吞吐量的特点。\nMapReduce：主要负责数据运算。\nYARN：主要负责集群资源和作业的调度。\n\nHadoop安装首先在 Hadoop官网下载 合适的版本，我这里选择的是3.2.2版本。推荐下载官方编译好的二进制安装包，源码会在后面CDH学习中使用到。\nHadoop是需要Java环境的，所以要确保机器已经安装好JDK（官方文档给出的最低要求是Java8），并且配置到全局环境变量中（大部分的大数据工具都需要Java环境，如果不配置全局环境变量就需要在每一个用户下对Java环境进行配置）。在生产环境安装部署时要先到 官网 确认JDK版本在不在问题列表中。\n\nMinimum required Java version increased from Java 7 to Java 8\nAll Hadoop JARs are now compiled targeting a runtime version of Java 8. Users still using Java 7 or below must upgrade to Java 8.\n\n1. 建立用户及文件夹首先在服务器上建立一个用户来管理及使用Hadoop。\n[root@Clay ~]$ useradd clay[root@Clay ~]$ id clayuid=1000(clay) gid=1000(clay) groups=1000(clay)\n\n然后要切换到新建好的clay用户，并且在clay用户的home目录下创建所需要的文件夹。\n[root@Clay ~]$ su - clay[ruoze@Clay ~]$ mkdir sourcecode software app log data lib tmp[ruoze@Clay ~]$ lltotal 28drwxrwxr-x 3 clay clay 4096 Nov 22 21:20 appdrwxrwxr-x 2 clay clay 4096 Nov 22 21:05 datadrwxrwxr-x 2 clay clay 4096 Nov 22 21:05 libdrwxrwxr-x 2 clay clay 4096 Nov 22 21:05 logdrwxrwxr-x 2 clay clay 4096 Nov 22 21:11 softwaredrwxrwxr-x 2 clay clay 4096 Nov 22 21:05 sourcecodedrwxrwxr-x 2 clay clay 4096 Nov 22 21:05 tmp\n\n\nTips:这里需要自建一个tmp目录。根据Linux系统的不同，默认的tmp目录定期不访问会自动清除。\n\n2.Hadoop解压安装做好前期的准备工作后，通过scp或rz将Hadoop压缩包传输到Linux服务器上。首先把压缩包移动到新建用户clay的home下，并修正权限确保不会出现Permission Denied的错误：\n[root@Clay ~]$ mv /tmp/hadoop-3.2.2.tar.gz /home/clay/software/[root@Clay ~]$ chown clay:clay /home/ruoze/software/* \n然后解压并创建软连接：\n[clay@Clay software]$ tar -xzvf hadoop-3.2.2.tar.gz -C ../app/ [clay@Clay software]$ cd ../app[clay@Clay app]$ ln -s hadoop-3.2.2 hadoop[clay@Clay app]$ lltotal 4lrwxrwxrwx  1 clay clay   13 Nov 22 21:20 hadoop -&gt; hadoop-3.2.2/drwxr-xr-x 12 clay clay 4096 Nov 25 20:59 hadoop-3.2.2[clay@Clay app] $ cd hadoop[clay@Clay hadoop]$ lltotal 216drwxr-xr-x 2 clay clay   4096 Jan  3  2021 bin # 存放命令执行脚本drwxr-xr-x 3 clay clay   4096 Jan  3  2021 etc # 存放Hadoop配置文件drwxr-xr-x 2 clay clay   4096 Jan  3  2021 includedrwxrwxr-x 2 clay clay   4096 Nov 24 21:48 inputdrwxr-xr-x 3 clay clay   4096 Jan  3  2021 libdrwxr-xr-x 4 clay clay   4096 Jan  3  2021 libexec-rw-rw-r-- 1 clay clay 150569 Dec  5  2020 LICENSE.txtdrwxrwxr-x 2 clay clay   4096 Nov 26 22:32 logs-rw-rw-r-- 1 clay clay  21943 Dec  5  2020 NOTICE.txtdrwxr-xr-x 3 clay clay   4096 Nov 25 21:09 output-rw-rw-r-- 1 clay clay   1361 Dec  5  2020 README.txtdrwxr-xr-x 3 clay clay   4096 Nov 26 21:16 sbin # 存放Hadoop启动停止脚本drwxr-xr-x 4 clay clay   4096 Jan  3  2021 share\n\n将Hadoop配置到当前用户的环境变量.bahsrc中\nexport HADOOP_HOME=/home/clay/app/hadoopexport PATH=$HADOOP_HOME/bin:$PATH[clay@Clay ~]$ source . .bashrc # 生效配置文件[clay@Clay ~]$ echo $HADOOP_HOME/ # 使用echo命令校验配置是否正确/home/clay/app/hadoop/[clay@Clay ~]$ which hadoop # 使用which校验配置是否正确~/app/hadoop/bin/hadoop\n\n3.Standalone模式Hadoop官方文档提到了Hadoop有三种部署模式：\n\nStandalone Mode：本地模式，不启动进程。基本不使用\nPseudo-Distributed Mode：伪分布式模式，会启动相关进程，但只有一个进程。学习使用\nFully-Distributed Mode：分布式模式。启动多个进程。生产使用\n\n根据 官方文档 给出的Standalone Mode测试案例：\n[clay@Clay hadoop]$ mkdir input[clay@Clay hadoop]$ ll[clay@Clay hadoop]$ cp etc/hadoop/*.xml input[clay@Clay hadoop]$ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar grep input output &#x27;dfs[a-z.]+&#x27;[clay@Clay hadoop]$ cat output/*[clay@Clay hadoop]$ cd output/[clay@Clay hadoop]$ lltotal 4-rw-r--r-- 1 root root 11 Nov 21 10:14 part-r-00000-rw-r--r-- 1 root root  0 Nov 21 10:14 _SUCCESS[clay@Clay hadoop]$ cat part-r-000001       dfsadmin \n\n4.Pseudo-Distributed模式伪分布式模式是要启动相关进程的，所以需要对Hadoop的配置文件进行修改。\n1. 首先要修改的是core-site.xml文件：[clay@Clay hadoop]$ vi etc/hadoop/core-site.xml&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;&lt;configuration&gt;   &lt;property&gt;        &lt;name&gt;fs.defaultFS&lt;/name&gt;        &lt;value&gt;hdfs://Clay:9000&lt;/value&gt;    &lt;/property&gt;&lt;/configuration&gt;\n\n2. 接下来修改hdfs-site.xml文件：[clay@Clay hadoop]$ vi etc/hadoop/hdfs-site.xml&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;&lt;configuration&gt;    &lt;property&gt;        &lt;name&gt;dfs.replication&lt;/name&gt;        &lt;value&gt;1&lt;/value&gt;    &lt;/property&gt;&lt;/configuration&gt;\n\n\nTips：注意修改配置文件时的用户。要使用之前新建的用户，而不是使用root用户。\n\n3. 因为伪分布式模式是需要运行进程，所以需要配置SSH免密登录。[clay@Clay ~]$  ssh-keygen # 生成秘钥[clay@Clay ~]$  cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys # 将公钥添加到授权的钥匙串中[clay@Clay ~]$  chmod 600 ~/.ssh/authorized_keys # ***重点：要赋予600权限，否则不能实现免密登录\n\n4. 前期准备工作完成，接下来格式化：[clay@Clay hadoop]$ bin/hdfs namenode -format\n\n5. 启动NameNode和DataNode：[clay@Clay hadoop]$ sbin/start-dfs.sh Starting namenodes on [Clay]Starting datanodesStarting secondary namenodes [Clay]\n\n6. 可以使用jps命令查看服务是否启动，但是最保险的是使用ps -ef | grep hadoop来查看：[clay@Clay hadoop]$ jps20633 SecondaryNameNode20842 Jps20410 DataNode20285 NameNode\n\n[clay@Clay hadoop]$ ps -ef | grep hadoopclay     20285     1  5 18:53 ?        00:00:07 /usr/java/java//bin/java -Dproc_namenode -Djava.net.preferIPv4Stack=true -Dhdfs.audit.logger=INFO,NullAppender -Dhadoop.security.logger=INFO,RFAS -Dyarn.log.dir=/home/clay/app/hadoop/logs -Dyarn.log.file=hadoop-clay-namenode-Clay.log -Dyarn.home.dir=/home/clay/app/hadoop -Dyarn.root.logger=INFO,console -Djava.library.path=/home/clay/app/hadoop/lib/native -Dhadoop.log.dir=/home/clay/app/hadoop/logs -Dhadoop.log.file=hadoop-clay-namenode-Clay.log -Dhadoop.home.dir=/home/clay/app/hadoop -Dhadoop.id.str=clay -Dhadoop.root.logger=INFO,RFA -Dhadoop.policy.file=hadoop-policy.xml org.apache.hadoop.hdfs.server.namenode.NameNodeclay     20410     1  5 18:53 ?        00:00:06 /usr/java/java//bin/java -Dproc_datanode -Djava.net.preferIPv4Stack=true -Dhadoop.security.logger=ERROR,RFAS -Dyarn.log.dir=/home/clay/app/hadoop/logs -Dyarn.log.file=hadoop-clay-datanode-Clay.log -Dyarn.home.dir=/home/clay/app/hadoop -Dyarn.root.logger=INFO,console -Djava.library.path=/home/clay/app/hadoop/lib/native -Dhadoop.log.dir=/home/clay/app/hadoop/logs -Dhadoop.log.file=hadoop-clay-datanode-Clay.log -Dhadoop.home.dir=/home/clay/app/hadoop -Dhadoop.id.str=clay -Dhadoop.root.logger=INFO,RFA -Dhadoop.policy.file=hadoop-policy.xml org.apache.hadoop.hdfs.server.datanode.DataNodeclay     20633     1  4 18:53 ?        00:00:05 /usr/java/java//bin/java -Dproc_secondarynamenode -Djava.net.preferIPv4Stack=true -Dhdfs.audit.logger=INFO,NullAppender -Dhadoop.security.logger=INFO,RFAS -Dyarn.log.dir=/home/clay/app/hadoop/logs -Dyarn.log.file=hadoop-clay-secondarynamenode-Clay.log -Dyarn.home.dir=/home/clay/app/hadoop -Dyarn.root.logger=INFO,console -Djava.library.path=/home/clay/app/hadoop/lib/native -Dhadoop.log.dir=/home/clay/app/hadoop/logs -Dhadoop.log.file=hadoop-clay-secondarynamenode-Clay.log -Dhadoop.home.dir=/home/clay/app/hadoop -Dhadoop.id.str=clay -Dhadoop.root.logger=INFO,RFA -Dhadoop.policy.file=hadoop-policy.xml org.apache.hadoop.hdfs.server.namenode.SecondaryNameNodeclay     20887 16629  0 18:55 pts/3    00:00:00 grep --color=auto hadoop\n\n7.HDFS的web界面访问查看hdfs的web界面，在2.x版本中默认的端口是50070，在3.x版本中默认的端口是9870。因为远程服务器是阿里云，所以要到阿里云机器管理的安全组中将9870端口放开。然后就可以在浏览器中查看hdfs的web界面。\n8. 运行官方测试案例首先先创建一个hdfs目录：\n[clay@Clay hadoop]$ bin/hdfs dfs -mkdir /user[clay@Clay hadoop]$ bin/hdfs dfs -mkdir /user/clay[clay@Clay hadoop]$ hdfs dfs -ls /userFound 1 itemsdrwxr-xr-x   - clay supergroup          0 2021-11-27 18:08 /user/clay[clay@Clay hadoop]$ bin/hdfs dfs -mkdir input # 在当前目录创建一个文件夹[clay@Clay hadoop]$ bin/hdfs dfs -put etc/hadoop/*.xml input # 将本地文件拷贝到hdfs上[clay@Clay hadoop]$ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar grep input output &#x27;dfs[a-z.]+&#x27; # 运行测试案例[clay@Clay hadoop]$ bin/hdfs dfs -get output output # 将存储在hdfs中的输出结果拷贝到本地[clay@Clay hadoop]$ cat output/*1       dfsadmin1       dfs.replication\n\n修改默认存储参数Hadoop的一些运行数据等参数都是默认存储到根目录的tmp目录中的。由于Linux系统机制的问题，tmp目录会定期进行清理。如果Hadoop的运行数据被清理，想要重启服务就会很麻烦。所以一定要在Hadoop的配置文件中修改默认存储路径到之前自建的tmp目录中。\n修改hdfs-site.xml文件，使HDFS的三个进程都运行在Clay这台机器上.这样配置的目的是为了IP变换后不需要逐个修改配置文件，只需要在/etc/hosts文件中修改即可。在hdfs-sit.xml文件中添加下列参数：\n&lt;property&gt;    &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;    &lt;value&gt;Clay:9868&lt;/value&gt;&lt;/property&gt;&lt;property&gt;    &lt;name&gt;dfs.namenode.secondary.https-address&lt;/name&gt;    &lt;value&gt;Clay:9869&lt;/value&gt;&lt;/property&gt;\n\nHDFS在启动时会生成一个.pid文件记录进程号，在停止服务时读取这个文件里的进程号来结束对应的进程。这个文件默认的存储位置同样是/etc/tmp目录下。如果pid文件被系统清除，那么此时在更新配置或jar包后，重启服务时DataNode并不会重启，还是之前的进程。所以需要将存储路径修改到自建的tmp目录中。在hadoop-env.sh文件中去掉注释并修改路径到自建tmp目录：\n# Where pid files are stored.  /tmp by default.export HADOOP_PID_DIR=/home/clay/tmp\n\n数据文件存储在默认tmp目录中同样是很危险的，所以需要修改存储路径。在core-site.xml文件中添加下面的配置：\n&lt;property&gt;    &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;    &lt;value&gt;/home/ruoze/tmp/hadoop-$&#123;user.name&#125;&lt;/value&gt;&lt;/property&gt;\n\n伪分布式模式下yarn的部署yarn组件启动后会有两个进程出现：ResourceManager和NodeManager。启动yarn之前需要先对mapred-site.xml进行配置，添加下列配置参数：\n&lt;property&gt;    &lt;name&gt;mapreduce.framework.name&lt;/name&gt;    &lt;value&gt;yarn&lt;/value&gt;&lt;/property&gt;&lt;property&gt;    &lt;name&gt;mapreduce.application.classpath&lt;/name&gt;\t                        &lt;value&gt;$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/*:$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/*&lt;/value&gt;&lt;/property&gt;\n\n还要对yarn-site.xml进行配置：\n&lt;property&gt;        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;yarn.nodemanager.env-whitelist&lt;/name&gt;        &lt;value&gt;JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME&lt;/value&gt;&lt;/property&gt;\n\n配置完成后使用sbin/yarn-start.sh启动yran组件。yarn的web界面默认是在8088端口，同样需要到安全组进行配置，开放该端口。\n\nTips：使用默认的8088端口会有被挖矿的风险。防患于未然，需要更改端口号。\n\nWordCount案例先在HDFS的根目录下新建一个input文件夹用来存储数据：\n[clay@Clay hadoop]$ hdfs dfs -mkdir /input\n\n然后在本地机器上准备一份数据，使用-put命令上传到HDFS中，并使用-cat参数来查看文件内容：\n[clay@Clay hadoop]$ vi 1.log[clay@Clay hadoop]$ hdfs dfs -ls /inputFound 1 items-rw-r--r--   1 clay supergroup         45 2021-11-29 22:33 /input/1.log[clay@Clay hadoop]$ hdfs dfs -cat /input/1.logclayclayhello worda s d fs a f dd f a s\n\n至此，数据准备阶段完成。接下来开始作业：\n[clay@Clay hadoop]$ find ./ -name &#x27;*example*&#x27;./libexec/hadoop-layout.sh.example./etc/hadoop/ssl-server.xml.example./etc/hadoop/shellprofile.d/example.sh./etc/hadoop/ssl-client.xml.example./etc/hadoop/hadoop-user-functions.sh.example./share/doc/hadoop/api/org/apache/hadoop/examples./share/doc/hadoop/api/org/apache/hadoop/security/authentication/examples./share/doc/hadoop/hadoop-mapreduce-examples./share/doc/hadoop/hadoop-auth-examples./share/doc/hadoop/hadoop-yarn/hadoop-yarn-common/apidocs/org/apache/hadoop/yarn/webapp/example./share/hadoop/mapreduce/lib-examples./share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar # 运行WC的jar包./share/hadoop/mapreduce/sources/hadoop-mapreduce-examples-3.2.2-test-sources.jar./share/hadoop/mapreduce/sources/hadoop-mapreduce-examples-3.2.2-sources.jar./share/hadoop/yarn/yarn-service-examples./lib/native/examples[clay@Clay hadoop]$ yarn jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar wordcount /input /output # 也可以使用hadoop命令来运行[clay@Clay hadoop]$ hdfs dfs -get /output[clay@Clay hadoop]$ cat output/*a       3clay    2d       3f       3hello   1s       3word    1\n\nWordCount案例完成，词频统计结果正确。\n","categories":["Hadoop"],"tags":["Hadoop"]},{"title":"Hadoop读、写文件流程","url":"/2021/11/15/read&write%20processing/","content":"Block在HDFS中有一个block的概念。假如有1000ml的水需要装到瓶子里，每个瓶子的容量是100ml，那么就需要10个瓶子；如果有1010ml的水，瓶子容量不变，需要的就是11个瓶子。最后剩下的不管有多少都会占用一个瓶子。这个例子中的水即是我们想要存放在HDFS中的文件大小，而瓶子对应的概念就是block。\n而block的大小是可以调整的。在hdfs-sit.xml文件中可以自定义block的大小，参数dfs.blocksize的默认大小是128MB。调整参数是根据使用场景来确定的。\nHDFS架构采用主从架构，在大部分的大数据组件中都是才用这用架构方式。一个主节点，带领多个从节点执行作业。\nNameNodeNameNode是名称节点，简称为NN，是集群中的主节点。NameNode所维护的信息包括：\n\n\n文件的名称\n文件的目录结构、权限、大小、所属用户和用户组、timestamp等信息\n文件被切割为哪些块，这些块（块+两个副本）分布在那些DataNode上。块映射(blockmap)。\nNameNode是不会持久化存储这种映射关系，是用过集群启动和运行的时候，DataNode定期给NameNode汇报(blockreport)，然后NameNode再内存中动态维护这种映射关系。\n\n\nNameNode的数据记录：\n-rw-rw-r-- 1 clay clay      42 Dec  6 20:45 edits_0000000000000000796-0000000000000000797-rw-rw-r-- 1 clay clay      42 Dec  6 21:45 edits_0000000000000000798-0000000000000000799-rw-rw-r-- 1 clay clay 1048576 Dec  6 21:45 edits_inprogress_0000000000000000800-rw-rw-r-- 1 clay clay    6434 Dec  6 20:45 fsimage_0000000000000000797-rw-rw-r-- 1 clay clay      62 Dec  6 20:45 fsimage_0000000000000000797.md5-rw-rw-r-- 1 clay clay    6434 Dec  6 21:45 fsimage_0000000000000000799-rw-rw-r-- 1 clay clay      62 Dec  6 21:45 fsimage_0000000000000000799.md5-rw-rw-r-- 1 clay clay       4 Dec  6 21:45 seen_txid-rw-rw-r-- 1 clay clay     216 Nov 29 20:05 VERSION\n\nedit开头的文件表示编辑日志文件；fsimage是镜像文件。实际读、写等操作的请求是记录到编辑日志文件中的。edits_inprogress是记录正在处理的请求。\nSecondaryNameNode(简称SNN)中记录的数据：\n-rw-rw-r-- 1 clay clay      42 Dec  6 20:45 edits_0000000000000000796-0000000000000000797-rw-rw-r-- 1 clay clay      42 Dec  6 21:45 edits_0000000000000000798-0000000000000000799-rw-rw-r-- 1 clay clay    6434 Dec  6 20:45 fsimage_0000000000000000797-rw-rw-r-- 1 clay clay      62 Dec  6 20:45 fsimage_0000000000000000797.md5-rw-rw-r-- 1 clay clay    6434 Dec  6 21:45 fsimage_0000000000000000799-rw-rw-r-- 1 clay clay      62 Dec  6 21:45 fsimage_0000000000000000799.md5-rw-rw-r-- 1 clay clay     216 Dec  6 21:45 VERSION\n\n在NameNode数据文件下可以看到有两个镜像文件，一个fsimage_0000000000000000797.md5和一个fsimage_0000000000000000799.md5。实际上799镜像文件时由797镜像文件与edits_0000000000000000798-0000000000000000799编辑日志文件合并得来的。合并的操作是由SecondartNameNode来执行的，生成fsimage_0000000000000000799，然后将镜像文件推送到NameNode。同时NameNode生成新的编辑日志文件edits_inprogress_0000000000000000800。\n从timestamp来看，每个文件的间隔时间都是一个小时。也就是说上述的操作每个小时会发生一次，这个操作叫做checkpoint检查点。checkpoint默认时间是1小时，可以在hdfs-site.xml文件中进行修改，参数为dsf.namenode.checkpoint.period；或者按照数据量进行，参数为dfs.namenode.checkpoint.txns。两个参数满足其一的时候就会执行checkpoint。\n在大数据早期的时候只有NN一个节点，如果NN挂掉，就会无法恢复。发展到中期的时候，SNN应运而生，定期来合并、备份和推送；但是如果在两次checkpoint之间NN挂掉，SNN恢复的就只能是上个checkpoint的数据，中间的数据就无法恢复。发展到现在，SNN也随之取消，取而代之的是新建一个实时的NN，作为高可靠HA；也就是说集群中会有两个NN，一个处于Active状态，另一个处于standby状态；当一个NameNode挂掉的时候，另一个NN就从standby状态转换成Active的状态继续提供服务。\nDataNodeDataNode是数据节点，简称为DN，是集群中的从节点，可以有多个DN。DN存储的文件内容包括：\n\n\n存储数据块和块的校验和\n定期给NN发送blockreport(块报告)\n\n\nblockreport默认的时间间隔是6小时，参数dfs.blockreport.intervalMsec可以修改块报告的间隔时间；还有一个参数dfs.directoryscan.interval的时间间隔也是6小时，这个参数的作用是让DN扫描磁盘空间内的数据文件的差异，生成报告发送给NN。\nHDFS写流程\nHDFS在写文件的时候用户是无感知的。写文件的具体流程是：\n\n首先hdfs client会调用FileSystem.creat方法和NN进行RCP通信。（上图中的1、2步骤）\nNN收到请求后会去检查这个文件是否存在、是否有权限创建这个文件等一系列校验操作。如果校验通过就创建一个新文件，但是这个文件没有数据，也不关联任何的block。创建之后NN会根据文件的大小、当前集群块大小和当前的DN节点情况，计算出文件要上传多少个块（包括副本）和这些块要上传到哪些DN节点。最后把这些信息返回给hdfs client的FSData OutputStream对象。（对应上图中的3）\n之后hdfs client调用FSDataStream对象中的write方法，根据集群的副本放置策略将第一个块的本身写到DN1，写完复制到DN2，DN2写完之后再复制写到DN3。（对应上图中的4）当三个副本全部写完的时候，DN3会返回一个ack package给DN2，DN2接收到后加上本身的确认信息后再将包传递给DN1，DN1收到后加上自己的确认信息再返回给FSDataStream，报告第一个块已全部写完，其他块的写入流程也是一样的。（对应上图中的5）\n当所有的块全部写完的时候，hdfs client会调用FSDataOutputstream对象中的close方法关闭输出流，再调用FileSystem.complete方法告诉NN文件写入成功。\n\nHDFS读流程\n读取文件的流程也是用户无感知的。具体流程如下：\n\n首先hdfs client会调用FileSystem的open方法和NN进行RCP通信。（上图中的1、2步骤）\n然后NameNode将文件的全部或者部分block列表返回给FSDataInputStream。（上图中的3）\nclient调用FSDataInputstrem的read方法去最近的一个存放有第一个块的DataNode进行读取。成功读取后进行校验，校验通过就关闭与DataNode的通信；假如校验失败，这记录块和DataNode的信息，下次就不从这个节点读取，而是从其他节点读取。然后读取最近的第二个块，以此类推。假如block列表全部读取完成之后文件还没有结束，就会向NameNode请求下一个批次的block列表。\n当文件读取完毕，client 调用FSDataInputStream对象的close方法关闭输入流。整个读取文件的流程结束。\n\n副本放置策略\n理论上读写操作尽量选择在DataNode节点上进行。这样第一个副本就会与clieant在同一个节点上，节省了网络IO的时间。第二个副本放置在不同机架上的某个节点。第三个副本放置在与第二个副本相同机架上的不同机器上。\n但是在实际生产上这样的放置策略会带来权限问题（第一个副本可以读取，第二、第三个副本由于在不同机器上可能会出现Permission Denied）。所以生产上真正的放置策略会有一个单独的client节点，既不是NameNode也不是DataNode节点。但是这样的放置策略与上面提到的就近原则相违背，其实网络IO在现在的环境中是可以忽略不计的，相较于可以忽略不计的IO，数据安全更为重要。\n","categories":["Hadoop"],"tags":["Hadoop"]}]