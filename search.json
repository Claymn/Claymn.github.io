[{"title":"在CentOS 7环境下编译Hadoop-2.7.7源码","url":"/2020/04/14/Hadoop-deploy/","content":"最近在学习Hadoop，所以下载了源码自己进行编译安装。虽然官网提供编译好的二进制包，但是由于系统版本的细微差别。所以决定自己动手编译，日后的工作中难免会要自定义源码中的组件，先学习如何编译源码，避免以后踩坑。\n环境准备系统环境：CentOS 7Hadoop版本：Hadoop-2.7.7\n编译所需要的组件先解压从官网下载的hadoop-2.7.7-src.tar.gz\ntar -zxvf hadoop-2.7.7-src.tar.gz -C /root/apps \n/root/apps可以换成其他想要的路径。然后进入到解压后的目录，查看BUILDING.txt文件编译Hadoop所需要的组件：\nBuild instructions for Hadoop----------------------------------------------------------------------------------Requirements:* Unix System* JDK 1.7+* Maven 3.0 or later* Findbugs 1.3.9 (if running findbugs)* ProtocolBuffer 2.5.0* CMake 2.6 or newer (if compiling native code), must be 3.0 or newer on Mac* Zlib devel (if compiling native code)* openssl devel ( if compiling native hadoop-pipes and to get the best HDFS encryption performance )* Linux FUSE (Filesystem in Userspace) version 2.6 or above ( if compiling fuse_dfs )* Internet connection for first build (to fetch all Maven and Hadoop dependencies)\n所以，我们需要在编译Hadoop之前先安装JDK、Maven、Ant、Findbugs、ProtocolBuffer、CMake、openssl、ncurses-devel。\n编译需要的包yum install cmakeyum install openssl-develyum install ncurses-devel\n\n编译需要的软件JDKLinux系统自带有java环境，但是并不是我们需要的。所以要先删除系统中自带的Java环境。\n// 卸载OpenJDKrpm -qa|grep javarpm -e --nodeps xxxxxxxxxx(OpenJDK的包)\n卸载掉OpenJDK以后再开始安装JDK：\n// 解压tar -zxvf jdk-8u231-linux-x64.tar.gz -C /root/apps// 将JDK的路径添加到环境变量中去vi ~/.bash_profileexport JAVA_HOME=/root/apps/jdk1.8.0_231export PATH=$PATH:$JAVA_HOME/binexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tool.jarsource ~/.bash_profile//  检查安装是否成功java -version// 下面的结果就是已经安装成功java version &quot;1.8.0_231&quot;Java(TM) SE Runtime Environment (build 1.8.0_231-b11)Java HotSpot(TM) 64-Bit Server VM (build 25.231-b11, mixed mode)\nMaven// 解压tar -zxvf apache-maven-3.3.9-bin.tar.gz -C /root/apps// 将maven路径添加到环境变量中vi ~/.bash_profileexport MAVEN_HOME=/root/apps/apache-maven-3.3.9export PATH=$MAVEN_HOME/bin:$PATHsource ~/.bash_profile// 检查是否安装成功mvn -vApache Maven 3.3.9 (bb52d8502b132ec0a5a3f4c09453c07478323dc5; 2015-11-11T00:41:47+08:00)Maven home: /root/apps/apache-maven-3.3.9Java version: 1.8.0_231, vendor: Oracle CorporationJava home: /root/apps/jdk1.8.0_231/jreDefault locale: zh_CN, platform encoding: UTF-8OS name: &quot;linux&quot;, version: &quot;3.10.0-1062.el7.x86_64&quot;, arch: &quot;amd64&quot;, family: &quot;unix&quot;\n\nAnt// 解压tar -zxvf apache-ant-1.9.14-bin.tar.gz -C /root/apps// 将路径添加到环境变量中vi ~/.bash_profileexport ANT_HOME=/root/apps/apache-ant-1.9.14export PATH=$ANT_HOME/bin:$PATHsource ~/.bash_profile// 检查是否安装成功ant -versionApache Ant(TM) version 1.9.14 compiled on March 12 2019\nFindbugs// 解压tar -zxvf findbugs-3.0.1.tar.gz -C /root/apps// 将路径添加到环境变量中vi ~/.bash_profileexport FIND_HOME=/root/apps/findbugs-3.0.1export PATH=$FIND_HOME/bin:$PATHsource ~/.bash_profile// 检查是否安装成功findbugs -version3.0.1\n\nProtocol Buffer// 安装C++依赖yum install gcc-c++// 解压tar -zxvf protobuf-2.5.0.tar.gz -C /root/apps// 编译后的文件如果需要放到其他文件目录mkdir /root/apps/protobuf// 在解压后的目录下配置编译好的软件安装目录./configure --prefix=/root/apps/protobuf// 编译make make install// 将路径添加到环境变量中vi ~/.bash_profileexport PROTO_HOME=/root/apps/protobuf-2.5export PATH=$PROTO_HOME/bin:$PATHsource ~/.bash_profile// 检查是否安装成功protoc --versionlibprotoc 2.5.0\n#编译Hadoop\n// 解压tar -zxvf hadoop-2.7.7-src.tar.gz -C /root/appscd hadoop-2.7.7-src// 开始编译mvn package -Pdisk,native -DskipTests -Dtar\n编译需要比较长的一段时间，编译好的.tar.gz存放在/root/apps/hadoop-2.7.7-src/hadoop-dist/target里。可以将编译好的安装包放到其他路径解压安装。解压安装之后也要将路径配置到环境变量中去，最后可以使用hadoop version命令来检查是否安装成功。\n","categories":["Hadoop"],"tags":["Hadoop"]},{"title":"Linux常用命令","url":"/2021/11/17/Linux%20command/","content":"Linux常用指令总结pwdpwd命令是用来查看当前光标所在的目录。\n[root@Clay usr]# pwd/usr\ncdcd命令是用来切换目录的。\n1. cd path(绝对路径/相对路径):切换到指定路径。2. cd :切换到当前用户的家目录。3. cd ~:功能同上。4. cd -：切换到上一次输入命令时所在的目录。5. cd ../:回退到上一级目录。6. cd ../../:回退到上两级目录。\nlsls命令是用来查看当前目录下有哪些文件和文件夹（没有具体信息，只展示名称。）ls命令还有很多可选参数：\n1. -l: 查看当前目录下文件、文件夹的详细信息。也可以使用ll命令查看，但不是所有Linux系统都支持ll命令。如果系统不支持可以配置alias来实现。    1.1 ll 文件夹名称: 查看当前目录下指定文件夹内的详细信息。2. -a: 查看当前目录下的所有文件、文件夹及隐藏文件。3. -h: 查看文件的大小(不是文件夹)。4. -r: 为所展示的文件、文件夹排序。5. -t: 以修改时间排序，参与-r参数组合使用。\nmkdirmkdir命令是用来创建文件夹的。可以级联创健也可以并行创建多个文件夹。\n1. mkdir 1/2/3    在当前目录创建一个名为1的文件夹，1文件夹下还有2文件夹，2文件夹下有3文件夹。2. mkdir 1 2 3    在当前目录下创建1、2、3三个独立的文件夹。\nmv &amp; cpmv指令可以移动文件到指定的文件夹，也可以用来重命名文件。\n1. mv A.log B.log :将A.log文件重命名为B.log。2. mv A path : 将A文件移动到指定路径下。3. mv A目录 B目录 : 如果B路径已存在，则将A目录移动到B目录下；若B目录不存在，则将A目录重命名为B目录。\ncp命令主要用来拷贝、复制文件或文件夹。\n1. cp 源文件 路径 : 将源文件拷贝到指定路径下。2. cp 目录 路径 : 将文件夹拷贝到指定路径下。\n查看文件内容查看文件内容常用的三个命令分别是：cat、more和less。使用方法都是命令+文件名。其中cat是一次性将文件内容全部展示到终端中。more和less这是分页显示。\n创建文件touch可以使用touch来创建文件。\ntouch + A : 创建一个名为A的空文件。 \n使用vi或者vim命令vi或vim也可以创建一个文件。\nvi + 文件名 : 创建一个空文件，指令执行后会进入命令行模式。vim + 文件名 : 创建一个空文件，指令执行后会进入命令行模式。\nechoecho &quot; &quot; &gt; 文件名\n也可以使用上面的命令来创建一个空文件。但是需要注意的是使用echo创建的文件没有内容，但是使用ll命令查看时会有1字节。 \n&gt; &amp; &gt;&gt;&gt;表示覆盖，&gt;&gt;表示追加。\n1. echo &quot;hello&quot; &gt; clay.log : 将“hello”写入到clay.log文件中，并覆盖之前的内容。[root@Clay ~]# cat clay.logHello world![root@Clay ~]# echo &quot;hello&quot; &gt; clay.log[root@Clay ~]# cat clay.loghello2. echo &quot;hello&quot; &gt;&gt; clay.log : 将“hello”追加到clay.log文件中，不覆盖之前内容。[root@Clay ~]# cat clay.logHello world[root@Clay ~]# echo &quot;hello&quot; &gt;&gt; clay.log[root@Clay ~]# cat clay.logHello worldhello\n环境变量环境变量分为：全局环境变量和个人环境变量。全局环境变量的配置文件在更目录下的/etc/profile中配置。配置完成后使用\nsource /etc/profile\n使配置文件生效。\n个人环境变量的配置文件在用户家目录下的.bash_profile和.bashrc文件中。生效命令同样使source。\nrmrm命令用来删除文件或文件夹。\nrm clay.log : 删除clay.log文件，删除前进行询问。rm -f clay.log : 强制删除clay.log文件，不询问。rm -r clay : 删除clay目录下的所有文件，删除前进行询问。rm -rf clay : 删除clay目录下的所有文件，删除前不询问。\n使用rm命令删除的文件、文件夹时无法恢复的，所以rm -rf命令要慎用。\nhistoryhistory可以用来查看输入命令历史。\n[root@Clay ~]# history    1  ls    2  mysql    3  ll -a    4  pwd    5  clear    6  logout    7  ls    8  ll -a[root@Clay ~]#\n可以使用!序号来执行历史命令。\n[root@Clay ~]# !3ll -a总用量 52dr-xr-x---.  5 root root 4096 11月 16 20:06 .dr-xr-xr-x. 18 root root 4096 11月 13 10:48 ..-rw-------   1 root root 2872 11月 16 20:34 .bash_history-rw-r--r--.  1 root root   18 12月 29 2013 .bash_logout-rw-r--r--.  1 root root  176 12月 29 2013 .bash_profile-rw-r--r--.  1 root root  176 12月 29 2013 .bashrcdrwxr-xr-x   3 root root 4096 7月  11 2019 .cache-rw-r--r--   1 root root   18 11月 16 20:09 clay.log-rw-r--r--.  1 root root  100 12月 29 2013 .cshrcdrwxr-xr-x   2 root root 4096 7月  11 2019 .pip-rw-r--r--   1 root root  205 11月  3 09:54 .pydistutils.cfgdrwx------   2 root root 4096 7月  11 2019 .ssh-rw-r--r--.  1 root root  129 12月 29 2013 .tcshrc[root@Clay ~]#\n还可以使用history -c来清除历史记录。\n管道符|是管道符，作用是连接两个命令，以第一个命令的输出作为第二个命令的输入。\ncat clay.log | wc -l : 统计clay.log文件中有多少行。[root@Clay ~]# cat clay.logHello worldhello[root@Clay ~]# cat clay.log | wc -l2cat clay.log | grep world : 模糊匹配clay.log文件中的词world。[root@Clay ~]# cat clay.logHello worldhello[root@Clay ~]# cat clay.log | grep worldHello world\n查看文件大小在Linux中查看文件大小可以使用ll -h来查看，效果如下：\n[root@Clay ~]# ll -h总用量 4.0K-rw-r--r-- 1 root root 18 11月 16 20:09 clay.log\n但是ll -h只能用来查看文件的大小，不能查看文件夹的大小。如果想要查看文件夹的大小可以使用 du -sh命令来查看。\n[root@Clay ~]# du -sh388K\t.[root@Clay ~]# du -sh clay.log4.0K\tclay.log\n查找文件查找文件可以使用find命令来实现。\nfind / -name &#x27;*clay*&#x27; : 全局搜索包含clay的文件。（两个*表示模糊搜索）[root@Clay ~]# find / -name &#x27;*clay*&#x27;/root/clay.logfind ./ -name &#x27;*clay*&#x27; : 在当前目录中搜索含有clay的文件find 路径 -name &#x27;*clay*&#x27; : 在指定的路径中搜索含有clay的文件。\n在生产环境中慎用全局搜索，资源占用较大。\n关于vivi有三种模式：命令行模式、编辑模式和尾行模式。vi + 文件名进入命令行模式。在命令行模式下按i进入编辑模式，这个时候就可以对文件内容进行编辑。在编辑完成后按ESC键，从编辑模式退到命令行模式，再按shift + :进入尾行模式，按wq保存并退出。\na. 光标移动 :    1. 使用方向键来控制光标的位置。    2. gg : 跳转到首行的第一个字符。    3. G : 跳转到最后一行。    4. nG : 跳转到第n行。gg命令相当于1G。    5. 0 : 将光标移动到当前行的首位。    6. $ : 将光标移动到当前行的末尾。b. 删除、复制、粘贴 :    1. dd : 删除光标所在的整行。    2. ndd : 以光标所在行开始，向下删除n行内容。    3. yy : 复制光标所在的那一行。    4. nyy : 以光标所在行开始，向下复制n行。    5. p, P : p为将已复制的内容粘贴到光标所在行的下一行；P为将已复制的内容粘贴到光标所在行的上一行。    6. u : 还原上一个操作。c. 搜索与替换 :    1. /+关键词 : 从光标开始，检索与关键词陪陪的字符串。    2.s/ : 用法是s/关键词/关键词2/g，关键词1为检索的字符串，关键词2为要替换的字符串，g表示全局替换。 d.尾行模式 :    1. q! : 强制退出。    2. wq : 保存并退出。    3. wq! : 强制保存并退出，可用来修改read only文件。e. 使用gg dG可以清空文件。\nTips : 如果想要从另一个机器的文件中拷贝内容到当前机器的文件中时，一定要进入编辑模式中进行拷贝。直接在命令行模式下拷贝内容会导致内容丢失。\n清空文件在生产中可以使用 :\ncat /dev/null &gt; clay.log\n来清空clay.log文件。也可以使用使用vi命令，在命令行模式下使用gg dG来清空文件内容。切勿使用echo &quot;&quot; &gt; clay.log对文件进行清空。这个操作虽然会清空文件内容，但是在ll命令查看时仍会有1字节内容。\n[root@Clay ~]# lltotal 4-rw-r--r-- 1 root root 18 Nov 16 20:09 clay.log[root@Clay ~]# echo &quot;&quot; &gt; clay.log [root@Clay ~]# lltotal 4-rw-r--r-- 1 root root 1 Nov 17 20:09 clay.log[root@Clay ~]# \n查看系统状态使用df -h查看磁盘状态 : \n[root@Clay ~]# df -hFilesystem      Size  Used Avail Use% Mounted on/dev/vda1        40G  4.1G   34G  11% /devtmpfs        3.9G     0  3.9G   0% /devtmpfs           3.9G     0  3.9G   0% /dev/shmtmpfs           3.9G  476K  3.9G   1% /runtmpfs           3.9G     0  3.9G   0% /sys/fs/cgrouptmpfs           783M     0  783M   0% /run/user/0[root@Clay ~]# \n使用free -m查看内存 : \n[root@Clay ~]# free -m              total        used        free      shared  buff/cache   availableMem:           7821         801        6382           0         637        6719Swap:             0           0           0[root@Clay ~]# \n使用top命令查看系统负载 : \n[root@Clay ~]# toptop - 20:34:49 up 4 days,  1:00,  1 user,  load average: 0.13, 0.05, 0.05Tasks:  97 total,   1 running,  96 sleeping,   0 stopped,   0 zombie%Cpu(s):  0.2 us,  0.3 sy,  0.0 ni, 99.6 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 stKiB Mem :  8008876 total,  6535356 free,   820704 used,   652816 buff/cacheKiB Swap:        0 total,        0 free,        0 used.  6880284 avail Mem   PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND     1861 root      10 -10  131856  16248  10604 S   2.7  0.2 131:33.99 AliYunDun   1381 root      20   0   42296   4364   2876 S   0.7  0.1   2:36.14 AliYunDunU+   22 root      rt   0       0      0      0 S   0.3  0.0   0:00.53 watchdog/3  2118 root      10 -10  436912   2792   2320 S   0.3  0.0   1:45.12 AliSecGuard    1 root      20   0  190976   3936   2608 S   0.0  0.0   0:16.59 systemd        2 root      20   0       0      0      0 S   0.0  0.0   0:00.00 kthreadd       3 root      20   0       0      0      0 S   0.0  0.0   0:00.05 ksoftirqd/0    5 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/0:+    6 root      20   0       0      0      0 S   0.0  0.0   0:00.17 kworker/u8+    7 root      rt   0       0      0      0 S   0.0  0.0   0:00.01 migration/0    8 root      20   0       0      0      0 S   0.0  0.0   0:00.00 rcu_bh         9 root      20   0       0      0      0 S   0.0  0.0   0:41.92 rcu_sched     10 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 lru-add-dr+   11 root      rt   0       0      0      0 S   0.0  0.0   0:00.96 watchdog/0    12 root      rt   0       0      0      0 S   0.0  0.0   0:00.51 watchdog/1    13 root      rt   0       0      0      0 S   0.0  0.0   0:00.02 migration/1   14 root      20   0       0      0      0 S   0.0  0.0   0:00.01 ksoftirqd/1\n查看系统负载的命令是实时更新的，按Ctrl + c退出。\n查看系统进程使用ps -ef查看系统进程，在使用是可以搭配管道符|来过滤想要查看的具体服务进程。\nClay:mysqladmin:/usr/local/mysql:&gt;ps -ef | grep mysqlmysqlad+  2128     1  0 Nov13 ?        00:00:00 /bin/sh /usr/local/mysql/bin/mysqld_safemysqlad+  2783  2128  0 Nov13 ?        00:02:48 /usr/local/mysql/bin/mysqld --basedir=/usr/local/mysql --datadir=/usr/local/mysql/data --plugin-dir=/usr/local/mysql/lib/plugin --log-error=/usr/local/mysql/data/hostname.err --pid-file=/usr/local/mysql/data/hostname.pid --socket=/usr/local/mysql/data/mysql.sock --port=3306root     14023 12185  0 20:43 pts/1    00:00:00 su - mysqladminmysqlad+ 14024 14023  0 20:43 pts/1    00:00:00 -bashmysqlad+ 14060 14024  0 20:44 pts/1    00:00:00 ps -efmysqlad+ 14061 14024  0 20:44 pts/1    00:00:00 grep --color=auto mysqlClay:mysqladmin:/usr/local/mysql:&gt;\n进程名后的数字为服务的PID, 第一组为此进程的PID, 第二组为父进程的PID, 数字1表示为系统进程。\n查询到进程的PID后可以使用kill -9 + PID强制结束该进程。\n网络相关查询IP地址使用ifconfig, 系统会在终端展示出网卡的相关信息。使用ping + IP地址来查看网络是否畅通。可以通过PID来查询服务是运行在哪个端口上的, 查询端口的命令为netstat -nlp : \nClay:mysqladmin:/usr/local/mysql:&gt;netstat -nlp | grep 2783(Not all processes could be identified, non-owned process info will not be shown, you would have to be root to see it all.)tcp6       0      0 :::3306                 :::*                    LISTEN     2783/mysqld         unix  2      [ ACC ]     STREAM     LISTENING     25101    2783/mysqld          /usr/local/mysql/data/mysql.sockClay:mysqladmin:/usr/local/mysql:&gt;\n可以看到mysqld服务是运行在3306端口。查询服务器的某个端口是否畅通可以使用telnet ip 端口号命令查询。\n权限相关在使用ll命令查看详细信息的时候会在前面出现一组字母和数字。这些字母和数字就代表了权限内容。\n\n\n\n权限\n字母\n数字\n\n\n\n读\nr\n4\n\n\n写\nw\n2\n\n\n执\nx\n1\n\n\n无权限\n-\n0\n\n\n例子：\n\n\n\n\n[root@Clay ~]# lltotal 4-rw-r--r-- 1 root root 1 Nov 17 20:09 clay.log[root@Clay ~]# \n第一位的字符串表示文件类型 : \n\n\n\n符号\n意义\n\n\n\n-\n表示普通文件\n\n\nd\n表示目录文件\n\n\nl\n表示软连接\n\n\n后面的字符三个为一组, 如clay.log文件的权限可以分为rw-、r--和r--三组。三组权限标识的含义为 : \n\n\n\n权限标识\n含义\n\n\n\nrw-\n表示文件所有者(u)的权限，这里的用户为root用户。所以root用户对文件可读可写不可执\n\n\nr–\n表示所属组(g)的权限，这里的用户组为root。所以表示root用户组对该文件可读不可写不可执\n\n\nr–\n表示其他用户组的所有用户(o)对该文件的权限。所以表示其他用户组对该文件可读不可写不可执\n\n\n权限是可以修改的，在linux中可以使用chmod命令来修改权限。chmod -R 777 文件/文件夹这条命令可以修改文件或文件夹为任意用户、用户组都有可读可写可执权限。单独赋予某个权限可以使用chmod 用户(u/g/o)+权限字符 文件/文件夹, 例如想要给clay.log加上可执权限 :\n[root@Clay ~]# chmod u+x clay.log [root@Clay ~]# lltotal 4-rwxr--r-- 1 root root 1 Nov 17 20:09 clay.log\n如果想要给root组的其他用户也赋予可写权限, 可以执行下面的命令 :\n[root@Clay ~]# chmod g+w clay.log [root@Clay ~]# lltotal 4-rwxrw-r-- 1 root root 1 Nov 17 20:09 clay.log\n取消权限的命令把+替换为-即可。除了修改文件/文件夹权限外，还可以通过修改所属来达到变更权限的目的。修改所属使用chown命令，chown -R 用户:用户组 文件夹/目录, 参数-R是以递归的方式修改目录的所属。在生产中通常遇到的Permission Denied都是由权限不足导致的，可以通过修改权限解决。关于权限的问题更加详细的内容可以查看这篇博客。\n临时获得root权限在/etc/sudoers文件中配置中加入想要获取root权限的用户 :\n## Allow root to run any commands anywhereroot    ALL=(ALL)       ALLclay    ALL=(root)      NOPASSWORD=ALL\n保存退出后，clay用户就可以不输入root用户密码的情况下使用sudo暂时获得root权限。\n解压 &amp; 压缩对于后缀为tar.gz的文件可以使用tar来执行解压 : \ntar -zxvf xxx.tar.gz : 解压到当前路径下tar -zxvf xxx.tar.gz -C path : 解压到指定路径下\n压缩的指令为 : \ntar -cvzf xxx.tar.gz 需要压缩的文件(如果是目录可以使用目录/*批量压缩)\n如果是zip压缩包，则使用 : \nunzip xxx.zip : 解压到当前目录unzip -d path xxx.zip : 解压到指定路径\n打包压缩 : \nzip xxx.zip 源文件如果需要压缩一个目录时需要添加 -r参数zip -r xxx.zip 目录\n获取帮助如果在使用一个命令是不知道命令后面有什么参数的时候可以使用命令 --help来查看命令帮助。也可以使用man 命令来查看。\n","categories":["Linux"],"tags":["Linux"]},{"title":"Spark源码编译","url":"/2019/10/13/Spark-compile/","content":"Spark源码编译环境：Mac OS 10.15；jdk 1.8；Spark-2.3.0；Maven-3.3.9。准备好环境以后，在Spark-2.3.0文件目录下运行\n./dev/make-distribution.sh --name 2.6.0-cdh5.7.0 --tgz -Pyarn -Phadoop-2.6 -Phive -Phive-thriftserver -Dhadoop.version=2.6.0-cdh5.7.0\n由于使用的是cdh版本的hadoop2.6.0，导致在编译时会出现错误：\n[ERROR] Failed to execute goal on project spark-launcher_2.11: Could not resolve dependencies for project org.apache.spark:spark-launcher_2.11:jar:2.3.0: Failure to find org.apache.hadoop:hadoop-client:jar:2.6.0-cdh5.7.0 in https://repo1.maven.org/maven2 was cached in the local repository, resolution will not be reattempted until the update interval of central has elapsed or updates are forced -&gt; [Help 1][ERROR] [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.[ERROR] Re-run Maven using the -X switch to enable full debug logging.[ERROR] [ERROR] For more information about the errors and possible solutions, please read the following articles:[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/DependencyResolutionException[ERROR] [ERROR] After correcting the problems, you can resume the build with the command[ERROR]   mvn &lt;goals&gt; -rf :spark-launcher_2.11\n在编译时会找不到包而导致编译失败。因为Spark默认的数据源是Apache，而在编译时使用的是cdh版本的hadoop。所以要在pom.xml文件中修改数据源。\n&lt;repositories&gt;    &lt;repository&gt;      &lt;id&gt;central&lt;/id&gt;      &lt;!-- This should be at top, it makes maven try the central repo first and then others and hence faster dep resolution --&gt;      &lt;name&gt;Maven Repository&lt;/name&gt;      &lt;url&gt;https://repo.maven.apache.org/maven2&lt;/url&gt;      &lt;releases&gt;        &lt;enabled&gt;true&lt;/enabled&gt;      &lt;/releases&gt;      &lt;snapshots&gt;        &lt;enabled&gt;false&lt;/enabled&gt;      &lt;/snapshots&gt;    &lt;/repository&gt;-----------------------------------------------------------------------------------------    &lt;repository&gt;      &lt;id&gt;cloudera&lt;/id&gt;      &lt;name&gt;cloudera Repository&lt;/name&gt;      &lt;url&gt;https://repository.cloudera.com/artifactory/cloudera-repos&lt;/url&gt;   &lt;/repository&gt;-----------------------------------------------------------------------------------------  &lt;/repositories&gt;\n在Spark的pom.xml文件中添加两横线中间的内容，将cloudera数据源添加进去。之后再按照Spark官网给出的编译指南进行编译即可。\n","categories":["Spark"],"tags":["Spark"]},{"title":"Hadoop安装与伪分布式部署","url":"/2021/11/27/hadoopdeploy/","content":"关于Hadoop广义上的Hadoop是指以Hadoop 软件为主的软件生态圈；狭义上的Hadoop则是指Hadoop软件本身。\nHadoop是由Apache基金会开发的一个分布式系统基础架构，也是Apache基金会的顶级项目之一。Hadoop可以充分利用集群的威力来进行高速运算和存储。Hadoop有三个核心组件：\n\nHDFS：分布式文件系统，主要的作用是用来存储数据。具有高容错、低成本、高吞吐量的特点。\nMapReduce：主要负责数据运算。\nYARN：主要负责集群资源和作业的调度。\n\nHadoop安装首先在 Hadoop官网下载 合适的版本，我这里选择的是3.2.2版本。推荐下载官方编译好的二进制安装包，源码会在后面CDH学习中使用到。\nHadoop是需要Java环境的，所以要确保机器已经安装好JDK（官方文档给出的最低要求是Java8），并且配置到全局环境变量中（大部分的大数据工具都需要Java环境，如果不配置全局环境变量就需要在每一个用户下对Java环境进行配置）。在生产环境安装部署时要先到 官网 确认JDK版本在不在问题列表中。\n\nMinimum required Java version increased from Java 7 to Java 8All Hadoop JARs are now compiled targeting a runtime version of Java 8. Users still using Java 7 or below must upgrade to Java 8.\n\n1. 建立用户及文件夹首先在服务器上建立一个用户来管理及使用Hadoop。\n[root@Clay ~]$ useradd clay[root@Clay ~]$ id clayuid=1000(clay) gid=1000(clay) groups=1000(clay)\n\n然后要切换到新建好的clay用户，并且在clay用户的home目录下创建所需要的文件夹。\n[root@Clay ~]$ su - clay[ruoze@Clay ~]$ mkdir sourcecode software app log data lib tmp[ruoze@Clay ~]$ lltotal 28drwxrwxr-x 3 clay clay 4096 Nov 22 21:20 appdrwxrwxr-x 2 clay clay 4096 Nov 22 21:05 datadrwxrwxr-x 2 clay clay 4096 Nov 22 21:05 libdrwxrwxr-x 2 clay clay 4096 Nov 22 21:05 logdrwxrwxr-x 2 clay clay 4096 Nov 22 21:11 softwaredrwxrwxr-x 2 clay clay 4096 Nov 22 21:05 sourcecodedrwxrwxr-x 2 clay clay 4096 Nov 22 21:05 tmp\n\n\nTips:这里需要自建一个tmp目录。根据Linux系统的不同，默认的tmp目录定期不访问会自动清除。\n\n2.Hadoop解压安装做好前期的准备工作后，通过scp或rz将Hadoop压缩包传输到Linux服务器上。首先把压缩包移动到新建用户clay的home下，并修正权限确保不会出现Permission Denied的错误：\n[root@Clay ~]$ mv /tmp/hadoop-3.2.2.tar.gz /home/clay/software/[root@Clay ~]$ chown clay:clay /home/ruoze/software/* \n然后解压并创建软连接：\n[clay@Clay software]$ tar -xzvf hadoop-3.2.2.tar.gz -C ../app/ [clay@Clay software]$ cd ../app[clay@Clay app]$ ln -s hadoop-3.2.2 hadoop[clay@Clay app]$ lltotal 4lrwxrwxrwx  1 clay clay   13 Nov 22 21:20 hadoop -&gt; hadoop-3.2.2/drwxr-xr-x 12 clay clay 4096 Nov 25 20:59 hadoop-3.2.2[clay@Clay app] $ cd hadoop[clay@Clay hadoop]$ lltotal 216drwxr-xr-x 2 clay clay   4096 Jan  3  2021 bin # 存放命令执行脚本drwxr-xr-x 3 clay clay   4096 Jan  3  2021 etc # 存放Hadoop配置文件drwxr-xr-x 2 clay clay   4096 Jan  3  2021 includedrwxrwxr-x 2 clay clay   4096 Nov 24 21:48 inputdrwxr-xr-x 3 clay clay   4096 Jan  3  2021 libdrwxr-xr-x 4 clay clay   4096 Jan  3  2021 libexec-rw-rw-r-- 1 clay clay 150569 Dec  5  2020 LICENSE.txtdrwxrwxr-x 2 clay clay   4096 Nov 26 22:32 logs-rw-rw-r-- 1 clay clay  21943 Dec  5  2020 NOTICE.txtdrwxr-xr-x 3 clay clay   4096 Nov 25 21:09 output-rw-rw-r-- 1 clay clay   1361 Dec  5  2020 README.txtdrwxr-xr-x 3 clay clay   4096 Nov 26 21:16 sbin # 存放Hadoop启动停止脚本drwxr-xr-x 4 clay clay   4096 Jan  3  2021 share\n\n将Hadoop配置到当前用户的环境变量.bahsrc中\nexport HADOOP_HOME=/home/clay/app/hadoopexport PATH=$HADOOP_HOME/bin:$PATH[clay@Clay ~]$ source . .bashrc # 生效配置文件[clay@Clay ~]$ echo $HADOOP_HOME/ # 使用echo命令校验配置是否正确/home/clay/app/hadoop/[clay@Clay ~]$ which hadoop # 使用which校验配置是否正确~/app/hadoop/bin/hadoop\n\n3.Standalone模式Hadoop官方文档提到了Hadoop有三种部署模式：\n\nStandalone Mode：本地模式，不启动进程。基本不使用\nPseudo-Distributed Mode：伪分布式模式，会启动相关进程，但只有一个进程。学习使用\nFully-Distributed Mode：分布式模式。启动多个进程。生产使用\n\n根据 官方文档 给出的Standalone Mode测试案例：\n[clay@Clay hadoop]$ mkdir input[clay@Clay hadoop]$ ll[clay@Clay hadoop]$ cp etc/hadoop/*.xml input[clay@Clay hadoop]$ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar grep input output &#x27;dfs[a-z.]+&#x27;[clay@Clay hadoop]$ cat output/*[clay@Clay hadoop]$ cd output/[clay@Clay hadoop]$ lltotal 4-rw-r--r-- 1 root root 11 Nov 21 10:14 part-r-00000-rw-r--r-- 1 root root  0 Nov 21 10:14 _SUCCESS[clay@Clay hadoop]$ cat part-r-000001       dfsadmin \n\n4.Pseudo-Distributed模式伪分布式模式是要启动相关进程的，所以需要对Hadoop的配置文件进行修改。\n1. 首先要修改的是core-site.xml文件：[clay@Clay hadoop]$ vi etc/hadoop/core-site.xml&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;&lt;configuration&gt;   &lt;property&gt;        &lt;name&gt;fs.defaultFS&lt;/name&gt;        &lt;value&gt;hdfs://Clay:9000&lt;/value&gt;    &lt;/property&gt;&lt;/configuration&gt;\n\n2. 接下来修改hdfs-site.xml文件：[clay@Clay hadoop]$ vi etc/hadoop/hdfs-site.xml&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;&lt;configuration&gt;    &lt;property&gt;        &lt;name&gt;dfs.replication&lt;/name&gt;        &lt;value&gt;1&lt;/value&gt;    &lt;/property&gt;&lt;/configuration&gt;\n\n\nTips：注意修改配置文件时的用户。要使用之前新建的用户，而不是使用root用户。\n\n3. 因为伪分布式模式是需要运行进程，所以需要配置SSH免密登录。[clay@Clay ~]$  ssh-keygen # 生成秘钥[clay@Clay ~]$  cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys # 将公钥添加到授权的钥匙串中[clay@Clay ~]$  chmod 600 ~/.ssh/authorized_keys # ***重点：要赋予600权限，否则不能实现免密登录\n\n4. 前期准备工作完成，接下来格式化：[clay@Clay hadoop]$ bin/hdfs namenode -format\n\n5. 启动NameNode和DataNode：[clay@Clay hadoop]$ sbin/start-dfs.sh Starting namenodes on [Clay]Starting datanodesStarting secondary namenodes [Clay]\n\n6. 可以使用jps命令查看服务是否启动，但是最保险的是使用ps -ef | grep hadoop来查看：[clay@Clay hadoop]$ jps20633 SecondaryNameNode20842 Jps20410 DataNode20285 NameNode\n\n[clay@Clay hadoop]$ ps -ef | grep hadoopclay     20285     1  5 18:53 ?        00:00:07 /usr/java/java//bin/java -Dproc_namenode -Djava.net.preferIPv4Stack=true -Dhdfs.audit.logger=INFO,NullAppender -Dhadoop.security.logger=INFO,RFAS -Dyarn.log.dir=/home/clay/app/hadoop/logs -Dyarn.log.file=hadoop-clay-namenode-Clay.log -Dyarn.home.dir=/home/clay/app/hadoop -Dyarn.root.logger=INFO,console -Djava.library.path=/home/clay/app/hadoop/lib/native -Dhadoop.log.dir=/home/clay/app/hadoop/logs -Dhadoop.log.file=hadoop-clay-namenode-Clay.log -Dhadoop.home.dir=/home/clay/app/hadoop -Dhadoop.id.str=clay -Dhadoop.root.logger=INFO,RFA -Dhadoop.policy.file=hadoop-policy.xml org.apache.hadoop.hdfs.server.namenode.NameNodeclay     20410     1  5 18:53 ?        00:00:06 /usr/java/java//bin/java -Dproc_datanode -Djava.net.preferIPv4Stack=true -Dhadoop.security.logger=ERROR,RFAS -Dyarn.log.dir=/home/clay/app/hadoop/logs -Dyarn.log.file=hadoop-clay-datanode-Clay.log -Dyarn.home.dir=/home/clay/app/hadoop -Dyarn.root.logger=INFO,console -Djava.library.path=/home/clay/app/hadoop/lib/native -Dhadoop.log.dir=/home/clay/app/hadoop/logs -Dhadoop.log.file=hadoop-clay-datanode-Clay.log -Dhadoop.home.dir=/home/clay/app/hadoop -Dhadoop.id.str=clay -Dhadoop.root.logger=INFO,RFA -Dhadoop.policy.file=hadoop-policy.xml org.apache.hadoop.hdfs.server.datanode.DataNodeclay     20633     1  4 18:53 ?        00:00:05 /usr/java/java//bin/java -Dproc_secondarynamenode -Djava.net.preferIPv4Stack=true -Dhdfs.audit.logger=INFO,NullAppender -Dhadoop.security.logger=INFO,RFAS -Dyarn.log.dir=/home/clay/app/hadoop/logs -Dyarn.log.file=hadoop-clay-secondarynamenode-Clay.log -Dyarn.home.dir=/home/clay/app/hadoop -Dyarn.root.logger=INFO,console -Djava.library.path=/home/clay/app/hadoop/lib/native -Dhadoop.log.dir=/home/clay/app/hadoop/logs -Dhadoop.log.file=hadoop-clay-secondarynamenode-Clay.log -Dhadoop.home.dir=/home/clay/app/hadoop -Dhadoop.id.str=clay -Dhadoop.root.logger=INFO,RFA -Dhadoop.policy.file=hadoop-policy.xml org.apache.hadoop.hdfs.server.namenode.SecondaryNameNodeclay     20887 16629  0 18:55 pts/3    00:00:00 grep --color=auto hadoop\n\n7.HDFS的web界面访问查看hdfs的web界面，在2.x版本中默认的端口是50070，在3.x版本中默认的端口是9870。因为远程服务器是阿里云，所以要到阿里云机器管理的安全组中将9870端口放开。然后就可以在浏览器中查看hdfs的web界面。\n8. 运行官方测试案例首先先创建一个hdfs目录：\n[clay@Clay hadoop]$ bin/hdfs dfs -mkdir /user[clay@Clay hadoop]$ bin/hdfs dfs -mkdir /user/clay[clay@Clay hadoop]$ hdfs dfs -ls /userFound 1 itemsdrwxr-xr-x   - clay supergroup          0 2021-11-27 18:08 /user/clay[clay@Clay hadoop]$ bin/hdfs dfs -mkdir input # 在当前目录创建一个文件夹[clay@Clay hadoop]$ bin/hdfs dfs -put etc/hadoop/*.xml input # 将本地文件拷贝到hdfs上[clay@Clay hadoop]$ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar grep input output &#x27;dfs[a-z.]+&#x27; # 运行测试案例[clay@Clay hadoop]$ bin/hdfs dfs -get output output # 将存储在hdfs中的输出结果拷贝到本地[clay@Clay hadoop]$ cat output/*1       dfsadmin1       dfs.replication\n\n修改默认存储参数Hadoop的一些运行数据等参数都是默认存储到根目录的tmp目录中的。由于Linux系统机制的问题，tmp目录会定期进行清理。如果Hadoop的运行数据被清理，想要重启服务就会很麻烦。所以一定要在Hadoop的配置文件中修改默认存储路径到之前自建的tmp目录中。\n修改hdfs-site.xml文件，使HDFS的三个进程都运行在Clay这台机器上.这样配置的目的是为了IP变换后不需要逐个修改配置文件，只需要在/etc/hosts文件中修改即可。在hdfs-sit.xml文件中添加下列参数：\n&lt;property&gt;    &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;    &lt;value&gt;Clay:9868&lt;/value&gt;&lt;/property&gt;&lt;property&gt;    &lt;name&gt;dfs.namenode.secondary.https-address&lt;/name&gt;    &lt;value&gt;Clay:9869&lt;/value&gt;&lt;/property&gt;\n\nHDFS在启动时会生成一个.pid文件记录进程号，在停止服务时读取这个文件里的进程号来结束对应的进程。这个文件默认的存储位置同样是/etc/tmp目录下。如果pid文件被系统清除，那么此时在更新配置或jar包后，重启服务时DataNode并不会重启，还是之前的进程。所以需要将存储路径修改到自建的tmp目录中。在hadoop-env.sh文件中去掉注释并修改路径到自建tmp目录：\n# Where pid files are stored.  /tmp by default.export HADOOP_PID_DIR=/home/clay/tmp\n\n数据文件存储在默认tmp目录中同样是很危险的，所以需要修改存储路径。在core-site.xml文件中添加下面的配置：\n&lt;property&gt;    &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;    &lt;value&gt;/home/ruoze/tmp/hadoop-$&#123;user.name&#125;&lt;/value&gt;&lt;/property&gt;\n\n伪分布式模式下yarn的部署yarn组件启动后会有两个进程出现：ResourceManager和NodeManager。启动yarn之前需要先对mapred-site.xml进行配置，添加下列配置参数：\n&lt;property&gt;    &lt;name&gt;mapreduce.framework.name&lt;/name&gt;    &lt;value&gt;yarn&lt;/value&gt;&lt;/property&gt;&lt;property&gt;    &lt;name&gt;mapreduce.application.classpath&lt;/name&gt;\t                        &lt;value&gt;$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/*:$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/*&lt;/value&gt;&lt;/property&gt;\n\n还要对yarn-site.xml进行配置：\n&lt;property&gt;        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;yarn.nodemanager.env-whitelist&lt;/name&gt;        &lt;value&gt;JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME&lt;/value&gt;&lt;/property&gt;\n\n配置完成后使用sbin/yarn-start.sh启动yran组件。yarn的web界面默认是在8088端口，同样需要到安全组进行配置，开放该端口。\n\nTips：使用默认的8088端口会有被挖矿的风险。防患于未然，需要更改端口号。\n\nWordCount案例先在HDFS的根目录下新建一个input文件夹用来存储数据：\n[clay@Clay hadoop]$ hdfs dfs -mkdir /input\n\n然后在本地机器上准备一份数据，使用-put命令上传到HDFS中，并使用-cat参数来查看文件内容：\n[clay@Clay hadoop]$ vi 1.log[clay@Clay hadoop]$ hdfs dfs -ls /inputFound 1 items-rw-r--r--   1 clay supergroup         45 2021-11-29 22:33 /input/1.log[clay@Clay hadoop]$ hdfs dfs -cat /input/1.logclayclayhello worda s d fs a f dd f a s\n\n至此，数据准备阶段完成。接下来开始作业：\n[clay@Clay hadoop]$ find ./ -name &#x27;*example*&#x27;./libexec/hadoop-layout.sh.example./etc/hadoop/ssl-server.xml.example./etc/hadoop/shellprofile.d/example.sh./etc/hadoop/ssl-client.xml.example./etc/hadoop/hadoop-user-functions.sh.example./share/doc/hadoop/api/org/apache/hadoop/examples./share/doc/hadoop/api/org/apache/hadoop/security/authentication/examples./share/doc/hadoop/hadoop-mapreduce-examples./share/doc/hadoop/hadoop-auth-examples./share/doc/hadoop/hadoop-yarn/hadoop-yarn-common/apidocs/org/apache/hadoop/yarn/webapp/example./share/hadoop/mapreduce/lib-examples./share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar # 运行WC的jar包./share/hadoop/mapreduce/sources/hadoop-mapreduce-examples-3.2.2-test-sources.jar./share/hadoop/mapreduce/sources/hadoop-mapreduce-examples-3.2.2-sources.jar./share/hadoop/yarn/yarn-service-examples./lib/native/examples[clay@Clay hadoop]$ yarn jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar wordcount /input /output # 也可以使用hadoop命令来运行[clay@Clay hadoop]$ hdfs dfs -get /output[clay@Clay hadoop]$ cat output/*a       3clay    2d       3f       3hello   1s       3word    1\n\nWordCount案例完成，词频统计结果正确。\n","categories":["Hadoop"],"tags":["Hadoop"]}]